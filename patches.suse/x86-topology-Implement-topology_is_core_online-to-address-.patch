From: Thomas Gleixner <tglx@linutronix.de>
Date: Sun, 21 Sep 2025 10:56:40 +0200
Subject: x86/topology: Implement topology_is_core_online() to address SMT
 regression
Git-commit: 2066f00e5b2dc061fb6d8c88fadaebc97f11feaa
Patch-mainline: v6.17
References: jsc#PED-13815

Christian reported that commit a430c11f4015 ("intel_idle: Rescan "dead" SMT
siblings during initialization") broke the use case in which both 'nosmt'
and 'maxcpus' are on the kernel command line because it onlines primary
threads, which were offline due to the maxcpus limit.

The initially proposed fix to skip primary threads in the loop is
inconsistent. While it prevents the primary thread to be onlined, it then
onlines the corresponding hyperthread(s), which does not really make sense.

The CPU iterator in cpuhp_smt_enable() contains a check which excludes all
threads of a core, when the primary thread is offline. The default
implementation is a NOOP and therefore not effective on x86.

Implement topology_is_core_online() on x86 to address this issue. This
makes the behaviour consistent between x86 and PowerPC.

Fixes: a430c11f4015 ("intel_idle: Rescan "dead" SMT siblings during initialization")
Fixes: f694481b1d31 ("ACPI: processor: Rescan "dead" SMT siblings during initialization")
Closes: https://lore.kernel.org/linux-pm/724616a2-6374-4ba3-8ce3-ea9c45e2ae3b@arm.com/
Reported-by: Christian Loehle <christian.loehle@arm.com>
Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
Reviewed-by: Rafael J. Wysocki (Intel) <rafael@kernel.org>
Tested-by: Christian Loehle <christian.loehle@arm.com>
Cc: stable@vger.kernel.org
Link: https://lore.kernel.org/12740505.O9o76ZdvQC@rafael.j.wysocki

Acked-by: Nikolay Borisov <nik.borisov@suse.com>
---
 arch/x86/include/asm/smp.h      |    1 +
 arch/x86/include/asm/topology.h |   11 +++++++++++
 arch/x86/kernel/cpu/topology.c  |   11 +++++++++++
 arch/x86/kernel/smpboot.c       |    7 +++++++
 4 files changed, 30 insertions(+)

--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -12,6 +12,7 @@ extern int smp_num_siblings;
 extern unsigned int num_processors;

 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_map);
+DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_copy_map);
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_core_map);
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_die_map);
 /* cpus sharing the last level cache: */
--- a/arch/x86/include/asm/topology.h
+++ b/arch/x86/include/asm/topology.h
@@ -143,6 +143,16 @@ int topology_update_die_map(unsigned int
 int topology_phys_to_logical_pkg(unsigned int pkg);
 int topology_phys_to_logical_die(unsigned int die, unsigned int cpu);
 bool topology_is_primary_thread(unsigned int cpu);
+int topology_get_primary_thread(unsigned int cpu);
+
+static inline bool topology_is_core_online(unsigned int cpu)
+{
+	int pcpu = topology_get_primary_thread(cpu);
+
+	return pcpu >= 0 ? cpu_online(pcpu) : false;
+}
+
+#define topology_is_core_online topology_is_core_online
 #else
 #define topology_max_packages()			(1)
 static inline int
@@ -155,6 +165,7 @@ static inline int topology_phys_to_logic
 static inline int topology_max_die_per_package(void) { return 1; }
 static inline int topology_max_smt_threads(void) { return 1; }
 static inline bool topology_is_primary_thread(unsigned int cpu) { return true; }
+static inline bool topology_is_core_online(unsigned int cpu) { return true; }
 #endif

 static inline void arch_fix_phys_package_id(int num, u32 slot)
--- a/arch/x86/kernel/cpu/topology.c
+++ b/arch/x86/kernel/cpu/topology.c
@@ -29,6 +29,17 @@ unsigned int __max_die_per_package __rea
 EXPORT_SYMBOL(__max_die_per_package);

 #ifdef CONFIG_SMP
+
+int topology_get_primary_thread(unsigned int cpu)
+{
+	int i;
+	for_each_cpu(i, per_cpu(cpu_sibling_copy_map, cpu)) {
+		if (topology_is_primary_thread(i))
+			return i;
+	}
+
+	return -ENODEV;
+}
 /*
  * Check if given CPUID extended topology "leaf" is implemented
  */
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -93,6 +93,8 @@
 DEFINE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_map);
 EXPORT_PER_CPU_SYMBOL(cpu_sibling_map);

+DEFINE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_copy_map);
+
 /* representing HT and core siblings of each logical CPU */
 DEFINE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_core_map);
 EXPORT_PER_CPU_SYMBOL(cpu_core_map);
@@ -664,6 +666,8 @@ void set_cpu_sibling_map(int cpu)
 		cpumask_set_cpu(cpu, topology_core_cpumask(cpu));
 		cpumask_set_cpu(cpu, topology_die_cpumask(cpu));
 		c->booted_cores = 1;
+		cpumask_copy(per_cpu(cpu_sibling_copy_map, cpu), topology_sibling_cpumask(cpu));
+
 		return;
 	}

@@ -686,6 +690,7 @@ void set_cpu_sibling_map(int cpu)
 			link_mask(topology_die_cpumask, cpu, i);
 	}

+	cpumask_copy(per_cpu(cpu_sibling_copy_map, cpu), topology_sibling_cpumask(cpu));
 	threads = cpumask_weight(topology_sibling_cpumask(cpu));
 	if (threads > __max_smt_threads)
 		__max_smt_threads = threads;
@@ -1424,6 +1429,7 @@ void __init smp_prepare_cpus_common(void

 	for_each_possible_cpu(i) {
 		zalloc_cpumask_var(&per_cpu(cpu_sibling_map, i), GFP_KERNEL);
+		zalloc_cpumask_var(&per_cpu(cpu_sibling_copy_map, i), GFP_KERNEL);
 		zalloc_cpumask_var(&per_cpu(cpu_core_map, i), GFP_KERNEL);
 		zalloc_cpumask_var(&per_cpu(cpu_die_map, i), GFP_KERNEL);
 		zalloc_cpumask_var(&per_cpu(cpu_llc_shared_map, i), GFP_KERNEL);
@@ -1666,6 +1672,7 @@ static void remove_siblinginfo(int cpu)
 	for_each_cpu(sibling, topology_die_cpumask(cpu))
 		cpumask_clear_cpu(cpu, topology_die_cpumask(sibling));

+
 	for_each_cpu(sibling, topology_sibling_cpumask(cpu)) {
 		cpumask_clear_cpu(cpu, topology_sibling_cpumask(sibling));
 		if (cpumask_weight(topology_sibling_cpumask(sibling)) == 1)
