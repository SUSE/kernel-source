From: Ravi Bangoria <ravi.bangoria@amd.com>
Date: Wed, 15 Jan 2025 05:44:37 +0000
Subject: perf/amd/ibs: Ceil sample_period to min_period
Git-commit: fa5d0a824e3bbd1f793d962f9e012ab0a8ee11c5
Patch-mainline: v6.15-rc1
References: jsc#PED-12756

The sample_period needs to be recalibrated after every sample to match
the desired sampling freq for a 'freq mode event'. Since the next
sample_period is calculated by generic kernel, PMU specific constraints
are not (explicitly) reckoned.

The sample_period value is programmed in a MaxCnt field of IBS PMUs, and
the MaxCnt field has following constraints:

1) MaxCnt must be multiple of 0x10.

  Kernel keeps track of residual / over-counted period into period_left,
  which should take care of this constraint by programming MaxCnt with
  (sample_period & ~0xF) and adding remaining period into the next sample.

2) MaxCnt must be >= 0x10 for IBS Fetch PMU and >= 0x90 for IBS Op PMU.

  Currently, IBS PMU driver allows sample_period below min_period, which
  is an undefined HW behavior. Reset sample_period to min_period whenever
  it's less than that.

Signed-off-by: Ravi Bangoria <ravi.bangoria@amd.com>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lkml.kernel.org/r/20250115054438.1021-9-ravi.bangoria@amd.com

Signed-off-by: Tony Jones <tonyj@suse.de>
---
 arch/x86/events/amd/ibs.c | 7 +++++++
 1 file changed, 7 insertions(+)

diff --git a/arch/x86/events/amd/ibs.c b/arch/x86/events/amd/ibs.c
index aea893a971b6..7978d7910adc 100644
--- a/arch/x86/events/amd/ibs.c
+++ b/arch/x86/events/amd/ibs.c
@@ -457,6 +457,9 @@ static void perf_ibs_start(struct perf_event *event, int flags)
 	WARN_ON_ONCE(!(hwc->state & PERF_HES_UPTODATE));
 	hwc->state = 0;
 
+	if (event->attr.freq && hwc->sample_period < perf_ibs->min_period)
+		hwc->sample_period = perf_ibs->min_period;
+
 	perf_ibs_set_period(perf_ibs, hwc, &period);
 	if (perf_ibs == &perf_ibs_op && (ibs_caps & IBS_CAPS_OPCNTEXT)) {
 		config |= period & IBS_OP_MAX_CNT_EXT_MASK;
@@ -1191,6 +1194,10 @@ static int perf_ibs_handle_irq(struct perf_ibs *perf_ibs, struct pt_regs *iregs)
 	perf_sample_save_callchain(&data, event, iregs);
 
 	throttle = perf_event_overflow(event, &data, &regs);
+
+	if (event->attr.freq && hwc->sample_period < perf_ibs->min_period)
+		hwc->sample_period = perf_ibs->min_period;
+
 out:
 	if (throttle) {
 		perf_ibs_stop(event, 0);

