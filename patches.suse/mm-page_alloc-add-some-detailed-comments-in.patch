From 91f761f47b690335a3eef72f6a78a2bdbbb02dfd Mon Sep 17 00:00:00 2001
From: gaoxiang17 <gaoxiang17@xiaomi.com>
Date: Fri, 20 Sep 2024 13:20:30 +0100
Subject: [PATCH] mm/page_alloc: add some detailed comments in

From 76cbca2435da0bb42130c895b9ba8d782861d768 Mon Sep 17 00:00:00 2001
 can_steal_fallback

References: bsc#1241169 (MM functional and performance backports)
Patch-mainline: v6.14-rc1
Git-commit: 6025ea5abbe5d813d6a41c78e6ea14259fb503f4

[akpm@linux-foundation.org: tweak grammar, fit to 80 cols]
Link: https://lkml.kernel.org/r/20240920122030.159751-1-gxxa03070307@gmail.com
Signed-off-by: gaoxiang17 <gaoxiang17@xiaomi.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Mel Gorman <mgorman@suse.de>

---
 mm/page_alloc.c | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 1c5ecc94b32d..579905c69716 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1855,6 +1855,14 @@ static bool can_steal_fallback(unsigned int order, int start_mt)
 	if (order >= pageblock_order)
 		return true;
 
+	/*
+	 * Movable pages won't cause permanent fragmentation, so when you alloc
+	 * small pages, you just need to temporarily steal unmovable or
+	 * reclaimable pages that are closest to the request size.  After a
+	 * while, memory compaction may occur to form large contiguous pages,
+	 * and the next movable allocation may not need to steal.  Unmovable and
+	 * reclaimable allocations need to actually steal pages.
+	 */
 	if (order >= pageblock_order / 2 ||
 		start_mt == MIGRATE_RECLAIMABLE ||
 		start_mt == MIGRATE_UNMOVABLE ||
