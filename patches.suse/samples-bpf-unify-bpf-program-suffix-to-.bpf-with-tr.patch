From: "Daniel T. Lee" <danieltimlee@gmail.com>
Date: Fri, 18 Aug 2023 18:01:13 +0900
Subject: samples/bpf: unify bpf program suffix to .bpf with tracing programs
Patch-mainline: v6.6-rc1
Git-commit: 4a0ee78890699706f59cc9bdf8283ecaa4e0a141
References: jsc#PED-6811

Currently, BPF programs typically have a suffix of .bpf.c. However,
some programs still utilize a mixture of _kern.c suffix alongside the
naming convention. In order to achieve consistency in the naming of
these programs, this commit unifies the inconsistency in the naming
convention of BPF kernel programs.

Signed-off-by: Daniel T. Lee <danieltimlee@gmail.com>
Link: https://lore.kernel.org/r/20230818090119.477441-4-danieltimlee@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
---
 samples/bpf/Makefile                           | 18 +++++++++---------
 .../{offwaketime_kern.c => offwaketime.bpf.c}  |  0
 samples/bpf/offwaketime_user.c                 |  2 +-
 .../bpf/{spintest_kern.c => spintest.bpf.c}    |  0
 samples/bpf/spintest_user.c                    |  2 +-
 samples/bpf/{tracex1_kern.c => tracex1.bpf.c}  |  0
 samples/bpf/tracex1_user.c                     |  2 +-
 samples/bpf/{tracex3_kern.c => tracex3.bpf.c}  |  0
 samples/bpf/tracex3_user.c                     |  2 +-
 samples/bpf/{tracex4_kern.c => tracex4.bpf.c}  |  0
 samples/bpf/tracex4_user.c                     |  2 +-
 samples/bpf/{tracex5_kern.c => tracex5.bpf.c}  |  0
 samples/bpf/tracex5_user.c                     |  2 +-
 samples/bpf/{tracex6_kern.c => tracex6.bpf.c}  |  0
 samples/bpf/tracex6_user.c                     |  2 +-
 samples/bpf/{tracex7_kern.c => tracex7.bpf.c}  |  0
 samples/bpf/Makefile           |   18 ++--
 samples/bpf/offwaketime.bpf.c  |  149 +++++++++++++++++++++++++++++++++++++++++
 samples/bpf/offwaketime_kern.c |  149 -----------------------------------------
 samples/bpf/offwaketime_user.c |    2 
 samples/bpf/spintest.bpf.c     |   71 +++++++++++++++++++
 samples/bpf/spintest_kern.c    |   71 -------------------
 samples/bpf/spintest_user.c    |    2 
 samples/bpf/tracex1.bpf.c      |   53 ++++++++++++++
 samples/bpf/tracex1_kern.c     |   53 --------------
 samples/bpf/tracex1_user.c     |    2 
 samples/bpf/tracex3.bpf.c      |   88 ++++++++++++++++++++++++
 samples/bpf/tracex3_kern.c     |   88 ------------------------
 samples/bpf/tracex3_user.c     |    2 
 samples/bpf/tracex4.bpf.c      |   54 ++++++++++++++
 samples/bpf/tracex4_kern.c     |   54 --------------
 samples/bpf/tracex4_user.c     |    2 
 samples/bpf/tracex5.bpf.c      |   92 +++++++++++++++++++++++++
 samples/bpf/tracex5_kern.c     |   92 -------------------------
 samples/bpf/tracex5_user.c     |    2 
 samples/bpf/tracex6.bpf.c      |   68 ++++++++++++++++++
 samples/bpf/tracex6_kern.c     |   68 ------------------
 samples/bpf/tracex6_user.c     |    2 
 samples/bpf/tracex7.bpf.c      |   15 ++++
 samples/bpf/tracex7_kern.c     |   15 ----
 samples/bpf/tracex7_user.c     |    2 
 25 files changed, 607 insertions(+), 607 deletions(-)
 rename samples/bpf/{offwaketime_kern.c => offwaketime.bpf.c} (100%)
 rename samples/bpf/{spintest_kern.c => spintest.bpf.c} (100%)
 rename samples/bpf/{tracex1_kern.c => tracex1.bpf.c} (100%)
 rename samples/bpf/{tracex3_kern.c => tracex3.bpf.c} (100%)
 rename samples/bpf/{tracex4_kern.c => tracex4.bpf.c} (100%)
 rename samples/bpf/{tracex5_kern.c => tracex5.bpf.c} (100%)
 rename samples/bpf/{tracex6_kern.c => tracex6.bpf.c} (100%)
 rename samples/bpf/{tracex7_kern.c => tracex7.bpf.c} (100%)

--- a/samples/bpf/Makefile
+++ b/samples/bpf/Makefile
@@ -124,21 +124,21 @@ always-y := $(tprogs-y)
 always-y += sockex1_kern.o
 always-y += sockex2_kern.o
 always-y += sockex3_kern.o
-always-y += tracex1_kern.o
+always-y += tracex1.bpf.o
 always-y += tracex2.bpf.o
-always-y += tracex3_kern.o
-always-y += tracex4_kern.o
-always-y += tracex5_kern.o
-always-y += tracex6_kern.o
-always-y += tracex7_kern.o
+always-y += tracex3.bpf.o
+always-y += tracex4.bpf.o
+always-y += tracex5.bpf.o
+always-y += tracex6.bpf.o
+always-y += tracex7.bpf.o
 always-y += sock_flags.bpf.o
 always-y += test_probe_write_user.bpf.o
 always-y += trace_output.bpf.o
 always-y += tcbpf1_kern.o
 always-y += tc_l2_redirect_kern.o
 always-y += lathist_kern.o
-always-y += offwaketime_kern.o
-always-y += spintest_kern.o
+always-y += offwaketime.bpf.o
+always-y += spintest.bpf.o
 always-y += map_perf_test.bpf.o
 always-y += test_overhead_tp.bpf.o
 always-y += test_overhead_raw_tp.bpf.o
@@ -333,7 +333,7 @@ $(obj)/xdp_redirect_user.o: $(obj)/xdp_r
 $(obj)/xdp_monitor_user.o: $(obj)/xdp_monitor.skel.h
 $(obj)/xdp_router_ipv4_user.o: $(obj)/xdp_router_ipv4.skel.h
 
-$(obj)/tracex5_kern.o: $(obj)/syscall_nrs.h
+$(obj)/tracex5.bpf.o: $(obj)/syscall_nrs.h
 $(obj)/hbm_out_kern.o: $(src)/hbm.h $(src)/hbm_kern.h
 $(obj)/hbm.o: $(src)/hbm.h
 $(obj)/hbm_edt_kern.o: $(src)/hbm.h $(src)/hbm_kern.h
--- /dev/null
+++ b/samples/bpf/offwaketime.bpf.c
@@ -0,0 +1,149 @@
+/* Copyright (c) 2016 Facebook
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of version 2 of the GNU General Public
+ * License as published by the Free Software Foundation.
+ */
+#include "vmlinux.h"
+#include <linux/version.h>
+#include <bpf/bpf_helpers.h>
+#include <bpf/bpf_tracing.h>
+
+#ifndef PERF_MAX_STACK_DEPTH
+#define PERF_MAX_STACK_DEPTH         127
+#endif
+
+#define _(P)                                                                   \
+	({                                                                     \
+		typeof(P) val;                                                 \
+		bpf_probe_read_kernel(&val, sizeof(val), &(P));                \
+		val;                                                           \
+	})
+
+#define MINBLOCK_US	1
+#define MAX_ENTRIES	10000
+
+struct key_t {
+	char waker[TASK_COMM_LEN];
+	char target[TASK_COMM_LEN];
+	u32 wret;
+	u32 tret;
+};
+
+struct {
+	__uint(type, BPF_MAP_TYPE_HASH);
+	__type(key, struct key_t);
+	__type(value, u64);
+	__uint(max_entries, MAX_ENTRIES);
+} counts SEC(".maps");
+
+struct {
+	__uint(type, BPF_MAP_TYPE_HASH);
+	__type(key, u32);
+	__type(value, u64);
+	__uint(max_entries, MAX_ENTRIES);
+} start SEC(".maps");
+
+struct wokeby_t {
+	char name[TASK_COMM_LEN];
+	u32 ret;
+};
+
+struct {
+	__uint(type, BPF_MAP_TYPE_HASH);
+	__type(key, u32);
+	__type(value, struct wokeby_t);
+	__uint(max_entries, MAX_ENTRIES);
+} wokeby SEC(".maps");
+
+struct {
+	__uint(type, BPF_MAP_TYPE_STACK_TRACE);
+	__uint(key_size, sizeof(u32));
+	__uint(value_size, PERF_MAX_STACK_DEPTH * sizeof(u64));
+	__uint(max_entries, MAX_ENTRIES);
+} stackmap SEC(".maps");
+
+#define STACKID_FLAGS (0 | BPF_F_FAST_STACK_CMP)
+
+SEC("kprobe/try_to_wake_up")
+int waker(struct pt_regs *ctx)
+{
+	struct task_struct *p = (void *) PT_REGS_PARM1(ctx);
+	struct wokeby_t woke;
+	u32 pid;
+
+	pid = _(p->pid);
+
+	bpf_get_current_comm(&woke.name, sizeof(woke.name));
+	woke.ret = bpf_get_stackid(ctx, &stackmap, STACKID_FLAGS);
+
+	bpf_map_update_elem(&wokeby, &pid, &woke, BPF_ANY);
+	return 0;
+}
+
+static inline int update_counts(void *ctx, u32 pid, u64 delta)
+{
+	struct wokeby_t *woke;
+	u64 zero = 0, *val;
+	struct key_t key;
+
+	__builtin_memset(&key.waker, 0, sizeof(key.waker));
+	bpf_get_current_comm(&key.target, sizeof(key.target));
+	key.tret = bpf_get_stackid(ctx, &stackmap, STACKID_FLAGS);
+	key.wret = 0;
+
+	woke = bpf_map_lookup_elem(&wokeby, &pid);
+	if (woke) {
+		key.wret = woke->ret;
+		__builtin_memcpy(&key.waker, woke->name, sizeof(key.waker));
+		bpf_map_delete_elem(&wokeby, &pid);
+	}
+
+	val = bpf_map_lookup_elem(&counts, &key);
+	if (!val) {
+		bpf_map_update_elem(&counts, &key, &zero, BPF_NOEXIST);
+		val = bpf_map_lookup_elem(&counts, &key);
+		if (!val)
+			return 0;
+	}
+	(*val) += delta;
+	return 0;
+}
+
+#if 1
+/* taken from /sys/kernel/tracing/events/sched/sched_switch/format */
+SEC("tracepoint/sched/sched_switch")
+int oncpu(struct trace_event_raw_sched_switch *ctx)
+{
+	/* record previous thread sleep time */
+	u32 pid = ctx->prev_pid;
+#else
+SEC("kprobe/finish_task_switch")
+int oncpu(struct pt_regs *ctx)
+{
+	struct task_struct *p = (void *) PT_REGS_PARM1(ctx);
+	/* record previous thread sleep time */
+	u32 pid = _(p->pid);
+#endif
+	u64 delta, ts, *tsp;
+
+	ts = bpf_ktime_get_ns();
+	bpf_map_update_elem(&start, &pid, &ts, BPF_ANY);
+
+	/* calculate current thread's delta time */
+	pid = bpf_get_current_pid_tgid();
+	tsp = bpf_map_lookup_elem(&start, &pid);
+	if (!tsp)
+		/* missed start or filtered */
+		return 0;
+
+	delta = bpf_ktime_get_ns() - *tsp;
+	bpf_map_delete_elem(&start, &pid);
+	delta = delta / 1000;
+	if (delta < MINBLOCK_US)
+		return 0;
+
+	return update_counts(ctx, pid, delta);
+}
+char _license[] SEC("license") = "GPL";
+u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/offwaketime_kern.c
+++ /dev/null
@@ -1,149 +0,0 @@
-/* Copyright (c) 2016 Facebook
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of version 2 of the GNU General Public
- * License as published by the Free Software Foundation.
- */
-#include "vmlinux.h"
-#include <linux/version.h>
-#include <bpf/bpf_helpers.h>
-#include <bpf/bpf_tracing.h>
-
-#ifndef PERF_MAX_STACK_DEPTH
-#define PERF_MAX_STACK_DEPTH         127
-#endif
-
-#define _(P)                                                                   \
-	({                                                                     \
-		typeof(P) val;                                                 \
-		bpf_probe_read_kernel(&val, sizeof(val), &(P));                \
-		val;                                                           \
-	})
-
-#define MINBLOCK_US	1
-#define MAX_ENTRIES	10000
-
-struct key_t {
-	char waker[TASK_COMM_LEN];
-	char target[TASK_COMM_LEN];
-	u32 wret;
-	u32 tret;
-};
-
-struct {
-	__uint(type, BPF_MAP_TYPE_HASH);
-	__type(key, struct key_t);
-	__type(value, u64);
-	__uint(max_entries, MAX_ENTRIES);
-} counts SEC(".maps");
-
-struct {
-	__uint(type, BPF_MAP_TYPE_HASH);
-	__type(key, u32);
-	__type(value, u64);
-	__uint(max_entries, MAX_ENTRIES);
-} start SEC(".maps");
-
-struct wokeby_t {
-	char name[TASK_COMM_LEN];
-	u32 ret;
-};
-
-struct {
-	__uint(type, BPF_MAP_TYPE_HASH);
-	__type(key, u32);
-	__type(value, struct wokeby_t);
-	__uint(max_entries, MAX_ENTRIES);
-} wokeby SEC(".maps");
-
-struct {
-	__uint(type, BPF_MAP_TYPE_STACK_TRACE);
-	__uint(key_size, sizeof(u32));
-	__uint(value_size, PERF_MAX_STACK_DEPTH * sizeof(u64));
-	__uint(max_entries, MAX_ENTRIES);
-} stackmap SEC(".maps");
-
-#define STACKID_FLAGS (0 | BPF_F_FAST_STACK_CMP)
-
-SEC("kprobe/try_to_wake_up")
-int waker(struct pt_regs *ctx)
-{
-	struct task_struct *p = (void *) PT_REGS_PARM1(ctx);
-	struct wokeby_t woke;
-	u32 pid;
-
-	pid = _(p->pid);
-
-	bpf_get_current_comm(&woke.name, sizeof(woke.name));
-	woke.ret = bpf_get_stackid(ctx, &stackmap, STACKID_FLAGS);
-
-	bpf_map_update_elem(&wokeby, &pid, &woke, BPF_ANY);
-	return 0;
-}
-
-static inline int update_counts(void *ctx, u32 pid, u64 delta)
-{
-	struct wokeby_t *woke;
-	u64 zero = 0, *val;
-	struct key_t key;
-
-	__builtin_memset(&key.waker, 0, sizeof(key.waker));
-	bpf_get_current_comm(&key.target, sizeof(key.target));
-	key.tret = bpf_get_stackid(ctx, &stackmap, STACKID_FLAGS);
-	key.wret = 0;
-
-	woke = bpf_map_lookup_elem(&wokeby, &pid);
-	if (woke) {
-		key.wret = woke->ret;
-		__builtin_memcpy(&key.waker, woke->name, sizeof(key.waker));
-		bpf_map_delete_elem(&wokeby, &pid);
-	}
-
-	val = bpf_map_lookup_elem(&counts, &key);
-	if (!val) {
-		bpf_map_update_elem(&counts, &key, &zero, BPF_NOEXIST);
-		val = bpf_map_lookup_elem(&counts, &key);
-		if (!val)
-			return 0;
-	}
-	(*val) += delta;
-	return 0;
-}
-
-#if 1
-/* taken from /sys/kernel/tracing/events/sched/sched_switch/format */
-SEC("tracepoint/sched/sched_switch")
-int oncpu(struct trace_event_raw_sched_switch *ctx)
-{
-	/* record previous thread sleep time */
-	u32 pid = ctx->prev_pid;
-#else
-SEC("kprobe/finish_task_switch")
-int oncpu(struct pt_regs *ctx)
-{
-	struct task_struct *p = (void *) PT_REGS_PARM1(ctx);
-	/* record previous thread sleep time */
-	u32 pid = _(p->pid);
-#endif
-	u64 delta, ts, *tsp;
-
-	ts = bpf_ktime_get_ns();
-	bpf_map_update_elem(&start, &pid, &ts, BPF_ANY);
-
-	/* calculate current thread's delta time */
-	pid = bpf_get_current_pid_tgid();
-	tsp = bpf_map_lookup_elem(&start, &pid);
-	if (!tsp)
-		/* missed start or filtered */
-		return 0;
-
-	delta = bpf_ktime_get_ns() - *tsp;
-	bpf_map_delete_elem(&start, &pid);
-	delta = delta / 1000;
-	if (delta < MINBLOCK_US)
-		return 0;
-
-	return update_counts(ctx, pid, delta);
-}
-char _license[] SEC("license") = "GPL";
-u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/offwaketime_user.c
+++ b/samples/bpf/offwaketime_user.c
@@ -105,7 +105,7 @@ int main(int argc, char **argv)
 		return 2;
 	}
 
-	snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
+	snprintf(filename, sizeof(filename), "%s.bpf.o", argv[0]);
 	obj = bpf_object__open_file(filename, NULL);
 	if (libbpf_get_error(obj)) {
 		fprintf(stderr, "ERROR: opening BPF object file failed\n");
--- /dev/null
+++ b/samples/bpf/spintest.bpf.c
@@ -0,0 +1,71 @@
+/* Copyright (c) 2016, Facebook
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of version 2 of the GNU General Public
+ * License as published by the Free Software Foundation.
+ */
+#include "vmlinux.h"
+#include <linux/version.h>
+#include <bpf/bpf_helpers.h>
+#include <bpf/bpf_tracing.h>
+
+#ifndef PERF_MAX_STACK_DEPTH
+#define PERF_MAX_STACK_DEPTH         127
+#endif
+
+struct {
+	__uint(type, BPF_MAP_TYPE_HASH);
+	__type(key, long);
+	__type(value, long);
+	__uint(max_entries, 1024);
+} my_map SEC(".maps");
+struct {
+	__uint(type, BPF_MAP_TYPE_PERCPU_HASH);
+	__uint(key_size, sizeof(long));
+	__uint(value_size, sizeof(long));
+	__uint(max_entries, 1024);
+} my_map2 SEC(".maps");
+
+struct {
+	__uint(type, BPF_MAP_TYPE_STACK_TRACE);
+	__uint(key_size, sizeof(u32));
+	__uint(value_size, PERF_MAX_STACK_DEPTH * sizeof(u64));
+	__uint(max_entries, 10000);
+} stackmap SEC(".maps");
+
+#define PROG(foo) \
+int foo(struct pt_regs *ctx) \
+{ \
+	long v = PT_REGS_IP(ctx), *val; \
+\
+	val = bpf_map_lookup_elem(&my_map, &v); \
+	bpf_map_update_elem(&my_map, &v, &v, BPF_ANY); \
+	bpf_map_update_elem(&my_map2, &v, &v, BPF_ANY); \
+	bpf_map_delete_elem(&my_map2, &v); \
+	bpf_get_stackid(ctx, &stackmap, BPF_F_REUSE_STACKID); \
+	return 0; \
+}
+
+/* add kprobes to all possible *spin* functions */
+SEC("kprobe/spin_unlock")PROG(p1)
+SEC("kprobe/spin_lock")PROG(p2)
+SEC("kprobe/mutex_spin_on_owner")PROG(p3)
+SEC("kprobe/rwsem_spin_on_owner")PROG(p4)
+SEC("kprobe/spin_unlock_irqrestore")PROG(p5)
+SEC("kprobe/_raw_spin_unlock_irqrestore")PROG(p6)
+SEC("kprobe/_raw_spin_unlock_bh")PROG(p7)
+SEC("kprobe/_raw_spin_unlock")PROG(p8)
+SEC("kprobe/_raw_spin_lock_irqsave")PROG(p9)
+SEC("kprobe/_raw_spin_trylock_bh")PROG(p10)
+SEC("kprobe/_raw_spin_lock_irq")PROG(p11)
+SEC("kprobe/_raw_spin_trylock")PROG(p12)
+SEC("kprobe/_raw_spin_lock")PROG(p13)
+SEC("kprobe/_raw_spin_lock_bh")PROG(p14)
+
+/* and to inner bpf helpers */
+SEC("kprobe/htab_map_update_elem")PROG(p15)
+SEC("kprobe/__htab_percpu_map_update_elem")PROG(p16)
+SEC("kprobe/htab_map_alloc")PROG(p17)
+
+char _license[] SEC("license") = "GPL";
+u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/spintest_kern.c
+++ /dev/null
@@ -1,71 +0,0 @@
-/* Copyright (c) 2016, Facebook
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of version 2 of the GNU General Public
- * License as published by the Free Software Foundation.
- */
-#include "vmlinux.h"
-#include <linux/version.h>
-#include <bpf/bpf_helpers.h>
-#include <bpf/bpf_tracing.h>
-
-#ifndef PERF_MAX_STACK_DEPTH
-#define PERF_MAX_STACK_DEPTH         127
-#endif
-
-struct {
-	__uint(type, BPF_MAP_TYPE_HASH);
-	__type(key, long);
-	__type(value, long);
-	__uint(max_entries, 1024);
-} my_map SEC(".maps");
-struct {
-	__uint(type, BPF_MAP_TYPE_PERCPU_HASH);
-	__uint(key_size, sizeof(long));
-	__uint(value_size, sizeof(long));
-	__uint(max_entries, 1024);
-} my_map2 SEC(".maps");
-
-struct {
-	__uint(type, BPF_MAP_TYPE_STACK_TRACE);
-	__uint(key_size, sizeof(u32));
-	__uint(value_size, PERF_MAX_STACK_DEPTH * sizeof(u64));
-	__uint(max_entries, 10000);
-} stackmap SEC(".maps");
-
-#define PROG(foo) \
-int foo(struct pt_regs *ctx) \
-{ \
-	long v = PT_REGS_IP(ctx), *val; \
-\
-	val = bpf_map_lookup_elem(&my_map, &v); \
-	bpf_map_update_elem(&my_map, &v, &v, BPF_ANY); \
-	bpf_map_update_elem(&my_map2, &v, &v, BPF_ANY); \
-	bpf_map_delete_elem(&my_map2, &v); \
-	bpf_get_stackid(ctx, &stackmap, BPF_F_REUSE_STACKID); \
-	return 0; \
-}
-
-/* add kprobes to all possible *spin* functions */
-SEC("kprobe/spin_unlock")PROG(p1)
-SEC("kprobe/spin_lock")PROG(p2)
-SEC("kprobe/mutex_spin_on_owner")PROG(p3)
-SEC("kprobe/rwsem_spin_on_owner")PROG(p4)
-SEC("kprobe/spin_unlock_irqrestore")PROG(p5)
-SEC("kprobe/_raw_spin_unlock_irqrestore")PROG(p6)
-SEC("kprobe/_raw_spin_unlock_bh")PROG(p7)
-SEC("kprobe/_raw_spin_unlock")PROG(p8)
-SEC("kprobe/_raw_spin_lock_irqsave")PROG(p9)
-SEC("kprobe/_raw_spin_trylock_bh")PROG(p10)
-SEC("kprobe/_raw_spin_lock_irq")PROG(p11)
-SEC("kprobe/_raw_spin_trylock")PROG(p12)
-SEC("kprobe/_raw_spin_lock")PROG(p13)
-SEC("kprobe/_raw_spin_lock_bh")PROG(p14)
-
-/* and to inner bpf helpers */
-SEC("kprobe/htab_map_update_elem")PROG(p15)
-SEC("kprobe/__htab_percpu_map_update_elem")PROG(p16)
-SEC("kprobe/htab_map_alloc")PROG(p17)
-
-char _license[] SEC("license") = "GPL";
-u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/spintest_user.c
+++ b/samples/bpf/spintest_user.c
@@ -23,7 +23,7 @@ int main(int ac, char **argv)
 		return 2;
 	}
 
-	snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
+	snprintf(filename, sizeof(filename), "%s.bpf.o", argv[0]);
 	obj = bpf_object__open_file(filename, NULL);
 	if (libbpf_get_error(obj)) {
 		fprintf(stderr, "ERROR: opening BPF object file failed\n");
--- /dev/null
+++ b/samples/bpf/tracex1.bpf.c
@@ -0,0 +1,53 @@
+/* Copyright (c) 2013-2015 PLUMgrid, http://plumgrid.com
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of version 2 of the GNU General Public
+ * License as published by the Free Software Foundation.
+ */
+#include "vmlinux.h"
+#include "net_shared.h"
+#include <linux/version.h>
+#include <bpf/bpf_helpers.h>
+#include <bpf/bpf_tracing.h>
+
+#define _(P)                                                                   \
+	({                                                                     \
+		typeof(P) val = 0;                                             \
+		bpf_probe_read_kernel(&val, sizeof(val), &(P));                \
+		val;                                                           \
+	})
+
+/* kprobe is NOT a stable ABI
+ * kernel functions can be removed, renamed or completely change semantics.
+ * Number of arguments and their positions can change, etc.
+ * In such case this bpf+kprobe example will no longer be meaningful
+ */
+SEC("kprobe/__netif_receive_skb_core")
+int bpf_prog1(struct pt_regs *ctx)
+{
+	/* attaches to kprobe __netif_receive_skb_core,
+	 * looks for packets on loobpack device and prints them
+	 */
+	char devname[IFNAMSIZ];
+	struct net_device *dev;
+	struct sk_buff *skb;
+	int len;
+
+	/* non-portable! works for the given kernel only */
+	bpf_probe_read_kernel(&skb, sizeof(skb), (void *)PT_REGS_PARM1(ctx));
+	dev = _(skb->dev);
+	len = _(skb->len);
+
+	bpf_probe_read_kernel(devname, sizeof(devname), dev->name);
+
+	if (devname[0] == 'l' && devname[1] == 'o') {
+		char fmt[] = "skb %p len %d\n";
+		/* using bpf_trace_printk() for DEBUG ONLY */
+		bpf_trace_printk(fmt, sizeof(fmt), skb, len);
+	}
+
+	return 0;
+}
+
+char _license[] SEC("license") = "GPL";
+u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex1_kern.c
+++ /dev/null
@@ -1,53 +0,0 @@
-/* Copyright (c) 2013-2015 PLUMgrid, http://plumgrid.com
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of version 2 of the GNU General Public
- * License as published by the Free Software Foundation.
- */
-#include "vmlinux.h"
-#include "net_shared.h"
-#include <linux/version.h>
-#include <bpf/bpf_helpers.h>
-#include <bpf/bpf_tracing.h>
-
-#define _(P)                                                                   \
-	({                                                                     \
-		typeof(P) val = 0;                                             \
-		bpf_probe_read_kernel(&val, sizeof(val), &(P));                \
-		val;                                                           \
-	})
-
-/* kprobe is NOT a stable ABI
- * kernel functions can be removed, renamed or completely change semantics.
- * Number of arguments and their positions can change, etc.
- * In such case this bpf+kprobe example will no longer be meaningful
- */
-SEC("kprobe/__netif_receive_skb_core")
-int bpf_prog1(struct pt_regs *ctx)
-{
-	/* attaches to kprobe __netif_receive_skb_core,
-	 * looks for packets on loobpack device and prints them
-	 */
-	char devname[IFNAMSIZ];
-	struct net_device *dev;
-	struct sk_buff *skb;
-	int len;
-
-	/* non-portable! works for the given kernel only */
-	bpf_probe_read_kernel(&skb, sizeof(skb), (void *)PT_REGS_PARM1(ctx));
-	dev = _(skb->dev);
-	len = _(skb->len);
-
-	bpf_probe_read_kernel(devname, sizeof(devname), dev->name);
-
-	if (devname[0] == 'l' && devname[1] == 'o') {
-		char fmt[] = "skb %p len %d\n";
-		/* using bpf_trace_printk() for DEBUG ONLY */
-		bpf_trace_printk(fmt, sizeof(fmt), skb, len);
-	}
-
-	return 0;
-}
-
-char _license[] SEC("license") = "GPL";
-u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex1_user.c
+++ b/samples/bpf/tracex1_user.c
@@ -12,7 +12,7 @@ int main(int ac, char **argv)
 	char filename[256];
 	FILE *f;
 
-	snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
+	snprintf(filename, sizeof(filename), "%s.bpf.o", argv[0]);
 	obj = bpf_object__open_file(filename, NULL);
 	if (libbpf_get_error(obj)) {
 		fprintf(stderr, "ERROR: opening BPF object file failed\n");
--- /dev/null
+++ b/samples/bpf/tracex3.bpf.c
@@ -0,0 +1,88 @@
+/* Copyright (c) 2013-2015 PLUMgrid, http://plumgrid.com
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of version 2 of the GNU General Public
+ * License as published by the Free Software Foundation.
+ */
+#include "vmlinux.h"
+#include <linux/version.h>
+#include <bpf/bpf_helpers.h>
+#include <bpf/bpf_tracing.h>
+
+struct {
+	__uint(type, BPF_MAP_TYPE_HASH);
+	__type(key, long);
+	__type(value, u64);
+	__uint(max_entries, 4096);
+} my_map SEC(".maps");
+
+/* kprobe is NOT a stable ABI. If kernel internals change this bpf+kprobe
+ * example will no longer be meaningful
+ */
+SEC("kprobe/blk_mq_start_request")
+int bpf_prog1(struct pt_regs *ctx)
+{
+	long rq = PT_REGS_PARM1(ctx);
+	u64 val = bpf_ktime_get_ns();
+
+	bpf_map_update_elem(&my_map, &rq, &val, BPF_ANY);
+	return 0;
+}
+
+static unsigned int log2l(unsigned long long n)
+{
+#define S(k) if (n >= (1ull << k)) { i += k; n >>= k; }
+	int i = -(n == 0);
+	S(32); S(16); S(8); S(4); S(2); S(1);
+	return i;
+#undef S
+}
+
+#define SLOTS 100
+
+struct {
+	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+	__uint(key_size, sizeof(u32));
+	__uint(value_size, sizeof(u64));
+	__uint(max_entries, SLOTS);
+} lat_map SEC(".maps");
+
+SEC("kprobe/__blk_account_io_done")
+int bpf_prog2(struct pt_regs *ctx)
+{
+	long rq = PT_REGS_PARM1(ctx);
+	u64 *value, l, base;
+	u32 index;
+
+	value = bpf_map_lookup_elem(&my_map, &rq);
+	if (!value)
+		return 0;
+
+	u64 cur_time = bpf_ktime_get_ns();
+	u64 delta = cur_time - *value;
+
+	bpf_map_delete_elem(&my_map, &rq);
+
+	/* the lines below are computing index = log10(delta)*10
+	 * using integer arithmetic
+	 * index = 29 ~ 1 usec
+	 * index = 59 ~ 1 msec
+	 * index = 89 ~ 1 sec
+	 * index = 99 ~ 10sec or more
+	 * log10(x)*10 = log2(x)*10/log2(10) = log2(x)*3
+	 */
+	l = log2l(delta);
+	base = 1ll << l;
+	index = (l * 64 + (delta - base) * 64 / base) * 3 / 64;
+
+	if (index >= SLOTS)
+		index = SLOTS - 1;
+
+	value = bpf_map_lookup_elem(&lat_map, &index);
+	if (value)
+		*value += 1;
+
+	return 0;
+}
+char _license[] SEC("license") = "GPL";
+u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex3_kern.c
+++ /dev/null
@@ -1,88 +0,0 @@
-/* Copyright (c) 2013-2015 PLUMgrid, http://plumgrid.com
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of version 2 of the GNU General Public
- * License as published by the Free Software Foundation.
- */
-#include "vmlinux.h"
-#include <linux/version.h>
-#include <bpf/bpf_helpers.h>
-#include <bpf/bpf_tracing.h>
-
-struct {
-	__uint(type, BPF_MAP_TYPE_HASH);
-	__type(key, long);
-	__type(value, u64);
-	__uint(max_entries, 4096);
-} my_map SEC(".maps");
-
-/* kprobe is NOT a stable ABI. If kernel internals change this bpf+kprobe
- * example will no longer be meaningful
- */
-SEC("kprobe/blk_mq_start_request")
-int bpf_prog1(struct pt_regs *ctx)
-{
-	long rq = PT_REGS_PARM1(ctx);
-	u64 val = bpf_ktime_get_ns();
-
-	bpf_map_update_elem(&my_map, &rq, &val, BPF_ANY);
-	return 0;
-}
-
-static unsigned int log2l(unsigned long long n)
-{
-#define S(k) if (n >= (1ull << k)) { i += k; n >>= k; }
-	int i = -(n == 0);
-	S(32); S(16); S(8); S(4); S(2); S(1);
-	return i;
-#undef S
-}
-
-#define SLOTS 100
-
-struct {
-	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
-	__uint(key_size, sizeof(u32));
-	__uint(value_size, sizeof(u64));
-	__uint(max_entries, SLOTS);
-} lat_map SEC(".maps");
-
-SEC("kprobe/__blk_account_io_done")
-int bpf_prog2(struct pt_regs *ctx)
-{
-	long rq = PT_REGS_PARM1(ctx);
-	u64 *value, l, base;
-	u32 index;
-
-	value = bpf_map_lookup_elem(&my_map, &rq);
-	if (!value)
-		return 0;
-
-	u64 cur_time = bpf_ktime_get_ns();
-	u64 delta = cur_time - *value;
-
-	bpf_map_delete_elem(&my_map, &rq);
-
-	/* the lines below are computing index = log10(delta)*10
-	 * using integer arithmetic
-	 * index = 29 ~ 1 usec
-	 * index = 59 ~ 1 msec
-	 * index = 89 ~ 1 sec
-	 * index = 99 ~ 10sec or more
-	 * log10(x)*10 = log2(x)*10/log2(10) = log2(x)*3
-	 */
-	l = log2l(delta);
-	base = 1ll << l;
-	index = (l * 64 + (delta - base) * 64 / base) * 3 / 64;
-
-	if (index >= SLOTS)
-		index = SLOTS - 1;
-
-	value = bpf_map_lookup_elem(&lat_map, &index);
-	if (value)
-		*value += 1;
-
-	return 0;
-}
-char _license[] SEC("license") = "GPL";
-u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex3_user.c
+++ b/samples/bpf/tracex3_user.c
@@ -125,7 +125,7 @@ int main(int ac, char **argv)
 		}
 	}
 
-	snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
+	snprintf(filename, sizeof(filename), "%s.bpf.o", argv[0]);
 	obj = bpf_object__open_file(filename, NULL);
 	if (libbpf_get_error(obj)) {
 		fprintf(stderr, "ERROR: opening BPF object file failed\n");
--- /dev/null
+++ b/samples/bpf/tracex4.bpf.c
@@ -0,0 +1,54 @@
+/* Copyright (c) 2015 PLUMgrid, http://plumgrid.com
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of version 2 of the GNU General Public
+ * License as published by the Free Software Foundation.
+ */
+#include "vmlinux.h"
+#include <linux/version.h>
+#include <bpf/bpf_helpers.h>
+#include <bpf/bpf_tracing.h>
+
+struct pair {
+	u64 val;
+	u64 ip;
+};
+
+struct {
+	__uint(type, BPF_MAP_TYPE_HASH);
+	__type(key, long);
+	__type(value, struct pair);
+	__uint(max_entries, 1000000);
+} my_map SEC(".maps");
+
+/* kprobe is NOT a stable ABI. If kernel internals change this bpf+kprobe
+ * example will no longer be meaningful
+ */
+SEC("kprobe/kmem_cache_free")
+int bpf_prog1(struct pt_regs *ctx)
+{
+	long ptr = PT_REGS_PARM2(ctx);
+
+	bpf_map_delete_elem(&my_map, &ptr);
+	return 0;
+}
+
+SEC("kretprobe/kmem_cache_alloc_node")
+int bpf_prog2(struct pt_regs *ctx)
+{
+	long ptr = PT_REGS_RC(ctx);
+	long ip = 0;
+
+	/* get ip address of kmem_cache_alloc_node() caller */
+	BPF_KRETPROBE_READ_RET_IP(ip, ctx);
+
+	struct pair v = {
+		.val = bpf_ktime_get_ns(),
+		.ip = ip,
+	};
+
+	bpf_map_update_elem(&my_map, &ptr, &v, BPF_ANY);
+	return 0;
+}
+char _license[] SEC("license") = "GPL";
+u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex4_kern.c
+++ /dev/null
@@ -1,54 +0,0 @@
-/* Copyright (c) 2015 PLUMgrid, http://plumgrid.com
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of version 2 of the GNU General Public
- * License as published by the Free Software Foundation.
- */
-#include "vmlinux.h"
-#include <linux/version.h>
-#include <bpf/bpf_helpers.h>
-#include <bpf/bpf_tracing.h>
-
-struct pair {
-	u64 val;
-	u64 ip;
-};
-
-struct {
-	__uint(type, BPF_MAP_TYPE_HASH);
-	__type(key, long);
-	__type(value, struct pair);
-	__uint(max_entries, 1000000);
-} my_map SEC(".maps");
-
-/* kprobe is NOT a stable ABI. If kernel internals change this bpf+kprobe
- * example will no longer be meaningful
- */
-SEC("kprobe/kmem_cache_free")
-int bpf_prog1(struct pt_regs *ctx)
-{
-	long ptr = PT_REGS_PARM2(ctx);
-
-	bpf_map_delete_elem(&my_map, &ptr);
-	return 0;
-}
-
-SEC("kretprobe/kmem_cache_alloc_node")
-int bpf_prog2(struct pt_regs *ctx)
-{
-	long ptr = PT_REGS_RC(ctx);
-	long ip = 0;
-
-	/* get ip address of kmem_cache_alloc_node() caller */
-	BPF_KRETPROBE_READ_RET_IP(ip, ctx);
-
-	struct pair v = {
-		.val = bpf_ktime_get_ns(),
-		.ip = ip,
-	};
-
-	bpf_map_update_elem(&my_map, &ptr, &v, BPF_ANY);
-	return 0;
-}
-char _license[] SEC("license") = "GPL";
-u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex4_user.c
+++ b/samples/bpf/tracex4_user.c
@@ -53,7 +53,7 @@ int main(int ac, char **argv)
 	char filename[256];
 	int map_fd, j = 0;
 
-	snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
+	snprintf(filename, sizeof(filename), "%s.bpf.o", argv[0]);
 	obj = bpf_object__open_file(filename, NULL);
 	if (libbpf_get_error(obj)) {
 		fprintf(stderr, "ERROR: opening BPF object file failed\n");
--- /dev/null
+++ b/samples/bpf/tracex5.bpf.c
@@ -0,0 +1,92 @@
+/* Copyright (c) 2015 PLUMgrid, http://plumgrid.com
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of version 2 of the GNU General Public
+ * License as published by the Free Software Foundation.
+ */
+#include "vmlinux.h"
+#include "syscall_nrs.h"
+#include <linux/version.h>
+#include <uapi/linux/unistd.h>
+#include <bpf/bpf_helpers.h>
+#include <bpf/bpf_tracing.h>
+
+#define __stringify(x) #x
+#define PROG(F) SEC("kprobe/"__stringify(F)) int bpf_func_##F
+
+struct {
+	__uint(type, BPF_MAP_TYPE_PROG_ARRAY);
+	__uint(key_size, sizeof(u32));
+	__uint(value_size, sizeof(u32));
+#ifdef __mips__
+	__uint(max_entries, 6000); /* MIPS n64 syscalls start at 5000 */
+#else
+	__uint(max_entries, 1024);
+#endif
+} progs SEC(".maps");
+
+SEC("kprobe/__seccomp_filter")
+int bpf_prog1(struct pt_regs *ctx)
+{
+	int sc_nr = (int)PT_REGS_PARM1(ctx);
+
+	/* dispatch into next BPF program depending on syscall number */
+	bpf_tail_call(ctx, &progs, sc_nr);
+
+	/* fall through -> unknown syscall */
+	if (sc_nr >= __NR_getuid && sc_nr <= __NR_getsid) {
+		char fmt[] = "syscall=%d (one of get/set uid/pid/gid)\n";
+		bpf_trace_printk(fmt, sizeof(fmt), sc_nr);
+	}
+	return 0;
+}
+
+/* we jump here when syscall number == __NR_write */
+PROG(SYS__NR_write)(struct pt_regs *ctx)
+{
+	struct seccomp_data sd;
+
+	bpf_probe_read_kernel(&sd, sizeof(sd), (void *)PT_REGS_PARM2(ctx));
+	if (sd.args[2] == 512) {
+		char fmt[] = "write(fd=%d, buf=%p, size=%d)\n";
+		bpf_trace_printk(fmt, sizeof(fmt),
+				 sd.args[0], sd.args[1], sd.args[2]);
+	}
+	return 0;
+}
+
+PROG(SYS__NR_read)(struct pt_regs *ctx)
+{
+	struct seccomp_data sd;
+
+	bpf_probe_read_kernel(&sd, sizeof(sd), (void *)PT_REGS_PARM2(ctx));
+	if (sd.args[2] > 128 && sd.args[2] <= 1024) {
+		char fmt[] = "read(fd=%d, buf=%p, size=%d)\n";
+		bpf_trace_printk(fmt, sizeof(fmt),
+				 sd.args[0], sd.args[1], sd.args[2]);
+	}
+	return 0;
+}
+
+#ifdef __NR_mmap2
+PROG(SYS__NR_mmap2)(struct pt_regs *ctx)
+{
+	char fmt[] = "mmap2\n";
+
+	bpf_trace_printk(fmt, sizeof(fmt));
+	return 0;
+}
+#endif
+
+#ifdef __NR_mmap
+PROG(SYS__NR_mmap)(struct pt_regs *ctx)
+{
+	char fmt[] = "mmap\n";
+
+	bpf_trace_printk(fmt, sizeof(fmt));
+	return 0;
+}
+#endif
+
+char _license[] SEC("license") = "GPL";
+u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex5_kern.c
+++ /dev/null
@@ -1,92 +0,0 @@
-/* Copyright (c) 2015 PLUMgrid, http://plumgrid.com
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of version 2 of the GNU General Public
- * License as published by the Free Software Foundation.
- */
-#include "vmlinux.h"
-#include "syscall_nrs.h"
-#include <linux/version.h>
-#include <uapi/linux/unistd.h>
-#include <bpf/bpf_helpers.h>
-#include <bpf/bpf_tracing.h>
-
-#define __stringify(x) #x
-#define PROG(F) SEC("kprobe/"__stringify(F)) int bpf_func_##F
-
-struct {
-	__uint(type, BPF_MAP_TYPE_PROG_ARRAY);
-	__uint(key_size, sizeof(u32));
-	__uint(value_size, sizeof(u32));
-#ifdef __mips__
-	__uint(max_entries, 6000); /* MIPS n64 syscalls start at 5000 */
-#else
-	__uint(max_entries, 1024);
-#endif
-} progs SEC(".maps");
-
-SEC("kprobe/__seccomp_filter")
-int bpf_prog1(struct pt_regs *ctx)
-{
-	int sc_nr = (int)PT_REGS_PARM1(ctx);
-
-	/* dispatch into next BPF program depending on syscall number */
-	bpf_tail_call(ctx, &progs, sc_nr);
-
-	/* fall through -> unknown syscall */
-	if (sc_nr >= __NR_getuid && sc_nr <= __NR_getsid) {
-		char fmt[] = "syscall=%d (one of get/set uid/pid/gid)\n";
-		bpf_trace_printk(fmt, sizeof(fmt), sc_nr);
-	}
-	return 0;
-}
-
-/* we jump here when syscall number == __NR_write */
-PROG(SYS__NR_write)(struct pt_regs *ctx)
-{
-	struct seccomp_data sd;
-
-	bpf_probe_read_kernel(&sd, sizeof(sd), (void *)PT_REGS_PARM2(ctx));
-	if (sd.args[2] == 512) {
-		char fmt[] = "write(fd=%d, buf=%p, size=%d)\n";
-		bpf_trace_printk(fmt, sizeof(fmt),
-				 sd.args[0], sd.args[1], sd.args[2]);
-	}
-	return 0;
-}
-
-PROG(SYS__NR_read)(struct pt_regs *ctx)
-{
-	struct seccomp_data sd;
-
-	bpf_probe_read_kernel(&sd, sizeof(sd), (void *)PT_REGS_PARM2(ctx));
-	if (sd.args[2] > 128 && sd.args[2] <= 1024) {
-		char fmt[] = "read(fd=%d, buf=%p, size=%d)\n";
-		bpf_trace_printk(fmt, sizeof(fmt),
-				 sd.args[0], sd.args[1], sd.args[2]);
-	}
-	return 0;
-}
-
-#ifdef __NR_mmap2
-PROG(SYS__NR_mmap2)(struct pt_regs *ctx)
-{
-	char fmt[] = "mmap2\n";
-
-	bpf_trace_printk(fmt, sizeof(fmt));
-	return 0;
-}
-#endif
-
-#ifdef __NR_mmap
-PROG(SYS__NR_mmap)(struct pt_regs *ctx)
-{
-	char fmt[] = "mmap\n";
-
-	bpf_trace_printk(fmt, sizeof(fmt));
-	return 0;
-}
-#endif
-
-char _license[] SEC("license") = "GPL";
-u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex5_user.c
+++ b/samples/bpf/tracex5_user.c
@@ -42,7 +42,7 @@ int main(int ac, char **argv)
 	char filename[256];
 	FILE *f;
 
-	snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
+	snprintf(filename, sizeof(filename), "%s.bpf.o", argv[0]);
 	obj = bpf_object__open_file(filename, NULL);
 	if (libbpf_get_error(obj)) {
 		fprintf(stderr, "ERROR: opening BPF object file failed\n");
--- /dev/null
+++ b/samples/bpf/tracex6.bpf.c
@@ -0,0 +1,68 @@
+#include "vmlinux.h"
+#include <linux/version.h>
+#include <bpf/bpf_helpers.h>
+
+struct {
+	__uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);
+	__uint(key_size, sizeof(int));
+	__uint(value_size, sizeof(u32));
+	__uint(max_entries, 64);
+} counters SEC(".maps");
+
+struct {
+	__uint(type, BPF_MAP_TYPE_HASH);
+	__type(key, int);
+	__type(value, u64);
+	__uint(max_entries, 64);
+} values SEC(".maps");
+
+struct {
+	__uint(type, BPF_MAP_TYPE_HASH);
+	__type(key, int);
+	__type(value, struct bpf_perf_event_value);
+	__uint(max_entries, 64);
+} values2 SEC(".maps");
+
+SEC("kprobe/htab_map_get_next_key")
+int bpf_prog1(struct pt_regs *ctx)
+{
+	u32 key = bpf_get_smp_processor_id();
+	u64 count, *val;
+	s64 error;
+
+	count = bpf_perf_event_read(&counters, key);
+	error = (s64)count;
+	if (error <= -2 && error >= -22)
+		return 0;
+
+	val = bpf_map_lookup_elem(&values, &key);
+	if (val)
+		*val = count;
+	else
+		bpf_map_update_elem(&values, &key, &count, BPF_NOEXIST);
+
+	return 0;
+}
+
+SEC("kprobe/htab_map_lookup_elem")
+int bpf_prog2(struct pt_regs *ctx)
+{
+	u32 key = bpf_get_smp_processor_id();
+	struct bpf_perf_event_value *val, buf;
+	int error;
+
+	error = bpf_perf_event_read_value(&counters, key, &buf, sizeof(buf));
+	if (error)
+		return 0;
+
+	val = bpf_map_lookup_elem(&values2, &key);
+	if (val)
+		*val = buf;
+	else
+		bpf_map_update_elem(&values2, &key, &buf, BPF_NOEXIST);
+
+	return 0;
+}
+
+char _license[] SEC("license") = "GPL";
+u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex6_kern.c
+++ /dev/null
@@ -1,68 +0,0 @@
-#include "vmlinux.h"
-#include <linux/version.h>
-#include <bpf/bpf_helpers.h>
-
-struct {
-	__uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);
-	__uint(key_size, sizeof(int));
-	__uint(value_size, sizeof(u32));
-	__uint(max_entries, 64);
-} counters SEC(".maps");
-
-struct {
-	__uint(type, BPF_MAP_TYPE_HASH);
-	__type(key, int);
-	__type(value, u64);
-	__uint(max_entries, 64);
-} values SEC(".maps");
-
-struct {
-	__uint(type, BPF_MAP_TYPE_HASH);
-	__type(key, int);
-	__type(value, struct bpf_perf_event_value);
-	__uint(max_entries, 64);
-} values2 SEC(".maps");
-
-SEC("kprobe/htab_map_get_next_key")
-int bpf_prog1(struct pt_regs *ctx)
-{
-	u32 key = bpf_get_smp_processor_id();
-	u64 count, *val;
-	s64 error;
-
-	count = bpf_perf_event_read(&counters, key);
-	error = (s64)count;
-	if (error <= -2 && error >= -22)
-		return 0;
-
-	val = bpf_map_lookup_elem(&values, &key);
-	if (val)
-		*val = count;
-	else
-		bpf_map_update_elem(&values, &key, &count, BPF_NOEXIST);
-
-	return 0;
-}
-
-SEC("kprobe/htab_map_lookup_elem")
-int bpf_prog2(struct pt_regs *ctx)
-{
-	u32 key = bpf_get_smp_processor_id();
-	struct bpf_perf_event_value *val, buf;
-	int error;
-
-	error = bpf_perf_event_read_value(&counters, key, &buf, sizeof(buf));
-	if (error)
-		return 0;
-
-	val = bpf_map_lookup_elem(&values2, &key);
-	if (val)
-		*val = buf;
-	else
-		bpf_map_update_elem(&values2, &key, &buf, BPF_NOEXIST);
-
-	return 0;
-}
-
-char _license[] SEC("license") = "GPL";
-u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex6_user.c
+++ b/samples/bpf/tracex6_user.c
@@ -180,7 +180,7 @@ int main(int argc, char **argv)
 	char filename[256];
 	int i = 0;
 
-	snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
+	snprintf(filename, sizeof(filename), "%s.bpf.o", argv[0]);
 	obj = bpf_object__open_file(filename, NULL);
 	if (libbpf_get_error(obj)) {
 		fprintf(stderr, "ERROR: opening BPF object file failed\n");
--- /dev/null
+++ b/samples/bpf/tracex7.bpf.c
@@ -0,0 +1,15 @@
+#include "vmlinux.h"
+#include <linux/version.h>
+#include <bpf/bpf_helpers.h>
+
+SEC("kprobe/open_ctree")
+int bpf_prog1(struct pt_regs *ctx)
+{
+	unsigned long rc = -12;
+
+	bpf_override_return(ctx, rc);
+	return 0;
+}
+
+char _license[] SEC("license") = "GPL";
+u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex7_kern.c
+++ /dev/null
@@ -1,15 +0,0 @@
-#include "vmlinux.h"
-#include <linux/version.h>
-#include <bpf/bpf_helpers.h>
-
-SEC("kprobe/open_ctree")
-int bpf_prog1(struct pt_regs *ctx)
-{
-	unsigned long rc = -12;
-
-	bpf_override_return(ctx, rc);
-	return 0;
-}
-
-char _license[] SEC("license") = "GPL";
-u32 _version SEC("version") = LINUX_VERSION_CODE;
--- a/samples/bpf/tracex7_user.c
+++ b/samples/bpf/tracex7_user.c
@@ -19,7 +19,7 @@ int main(int argc, char **argv)
 		return 0;
 	}
 
-	snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
+	snprintf(filename, sizeof(filename), "%s.bpf.o", argv[0]);
 	obj = bpf_object__open_file(filename, NULL);
 	if (libbpf_get_error(obj)) {
 		fprintf(stderr, "ERROR: opening BPF object file failed\n");
