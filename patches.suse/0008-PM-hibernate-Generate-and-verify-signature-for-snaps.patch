From 71d8a8950aaf2fc5ed81ce75106e62955b835153 Mon Sep 17 00:00:00 2001
From: "Lee, Chun-Yi" <jlee@suse.com>
Date: Tue, 12 Dec 2017 16:37:58 +0800
Subject: [PATCH 08/11] PM / hibernate: Generate and verify signature for
 snapshot image
Patch-mainline: Never, SUSE-specific
References: fate#316350

When producing memory snapshot image, hibernation uses HMAC-SHA512
with EFI secret key to calculate the hash for all data pages in image.
The hash result will be kept in the snapshot header as the image
signature. Before hibernation restores system, kernel executes
HMAC-SHA512 again and compares the result with the signature in header
to verify the integrity of snapshot image.

If the verification failed, the resume process will be stopped. The
snapshot image will be discarded and system will boot as normal.

Joey Lee:
This patch will be replaced after hibernation encryption with TPM
is ready on mainline. It needs some big changes after review by
upstream:
 - Simplify the design: remove keyring dependency and trampoline.
 - Encrypted whole snapshot image instead of only data pages.
 - Using TPM:
        - Direct use TPM API in hibernation instead of keyring
        - Localities (suggested by James Bottomley)

Link: https://lkml.org/lkml/2019/1/3/281
Signed-off-by: Lee, Chun-Yi <jlee@suse.com>
---
 kernel/power/Kconfig     |   13 ++
 kernel/power/hibernate.c |    9 +
 kernel/power/power.h     |   14 ++
 kernel/power/snapshot.c  |  291 ++++++++++++++++++++++++++++++++++++++++++++---
 kernel/power/swap.c      |    5 
 kernel/power/user.c      |    4 
 6 files changed, 316 insertions(+), 20 deletions(-)

--- a/kernel/power/Kconfig
+++ b/kernel/power/Kconfig
@@ -80,6 +80,19 @@ config HIBERNATION
 
 	  For more information take a look at <file:Documentation/power/swsusp.rst>.
 
+config HIBERNATE_VERIFICATION
+	bool "Hibernate verification"
+	depends on HIBERNATION
+	select EFI_SECRET_KEY
+	select CRYPTO_HMAC
+	select CRYPTO_SHA512
+	help
+	  This option provides support for generating and verifying the
+	  signature of memory snapshot image by HMAC-SHA512. Current mechanism
+	  relies on UEFI secure boot environment, EFI stub generates HMAC
+	  key for hibernate verification. This function will be bypassed on
+	  legacy BIOS.
+
 config HIBERNATION_SNAPSHOT_DEV
 	bool "Userspace snapshot device"
 	depends on HIBERNATION
--- a/kernel/power/hibernate.c
+++ b/kernel/power/hibernate.c
@@ -304,10 +304,14 @@ static int create_image(int platform_mod
 {
 	int error;
 
+	error = swsusp_prepare_hash(false);
+	if (error)
+		return error;
+
 	error = dpm_suspend_end(PMSG_FREEZE);
 	if (error) {
 		pr_err("Some devices failed to power down, aborting\n");
-		return error;
+		goto finish_hash;
 	}
 
 	error = platform_pre_snapshot(platform_mode);
@@ -368,6 +372,9 @@ static int create_image(int platform_mod
 	dpm_resume_start(in_suspend ?
 		(error ? PMSG_RECOVER : PMSG_THAW) : PMSG_RESTORE);
 
+ finish_hash:
+	swsusp_finish_hash();
+
 	return error;
 }
 
--- a/kernel/power/power.h
+++ b/kernel/power/power.h
@@ -8,6 +8,10 @@
 #include <linux/cpuidle.h>
 #include <linux/crypto.h>
 
+/* HMAC algorithm for hibernate snapshot signature */
+#define SNAPSHOT_HMAC	"hmac(sha512)"
+#define SNAPSHOT_DIGEST_SIZE 64
+
 struct swsusp_info {
 	struct new_utsname	uts;
 	u32			version_code;
@@ -17,6 +21,7 @@ struct swsusp_info {
 	unsigned long		pages;
 	unsigned long		size;
 	unsigned long           trampoline_pfn;
+	u8                      signature[SNAPSHOT_DIGEST_SIZE];
 } __aligned(PAGE_SIZE);
 
 #ifdef CONFIG_HIBERNATION
@@ -160,6 +165,15 @@ extern int snapshot_create_trampoline(vo
 extern void snapshot_init_trampoline(void);
 extern void snapshot_restore_trampoline(void);
 extern void snapshot_free_trampoline(void);
+#ifdef CONFIG_HIBERNATE_VERIFICATION
+extern int snapshot_image_verify(void);
+extern int swsusp_prepare_hash(bool may_sleep);
+extern void swsusp_finish_hash(void);
+#else
+static inline int snapshot_image_verify(void) { return 0; }
+static inline int swsusp_prepare_hash(bool may_sleep) { return 0; }
+static inline void swsusp_finish_hash(void) {}
+#endif
 
 extern bool hibernate_acquire(void);
 extern void hibernate_release(void);
--- a/kernel/power/snapshot.c
+++ b/kernel/power/snapshot.c
@@ -33,11 +33,15 @@
 #include <linux/set_memory.h>
 #include <linux/security.h>
 #include <linux/efi.h>
+#include <linux/vmalloc.h>
 
 #include <linux/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlbflush.h>
 #include <asm/io.h>
+#ifdef CONFIG_HIBERNATE_VERIFICATION
+#include <crypto/hash.h>
+#endif
 
 #include "power.h"
 
@@ -119,6 +123,7 @@ static inline void hibernate_unmap_page(
  * to image kernel.
  */
 struct trampoline {
+	int sig_verify_ret;
 	bool secret_key_valid;
 	u8 secret_key[SECRET_KEY_SIZE];
 };
@@ -1541,29 +1546,229 @@ static inline int copy_data_page(unsigne
 }
 #endif /* CONFIG_HIGHMEM */
 
+/* Total number of image pages */
+static unsigned int nr_copy_pages;
+/* Number of zero pages */
+static unsigned int nr_zero_pages;
+
+/* Point array for collecting buffers' address in snapshot_write_next() */
+static void **h_buf;
+
+#ifdef CONFIG_HIBERNATE_VERIFICATION
 /*
- * Copy data pages will copy all pages into pages pulled from the copy_bm.
- * If a page was entirely filled with zeros it will be marked in the zero_bm.
- *
- * Returns the number of pages copied.
+ * Signature of snapshot image
  */
-static unsigned long copy_data_pages(struct memory_bitmap *copy_bm,
+static u8 signature[SNAPSHOT_DIGEST_SIZE];
+
+/* Keep the signature verification result for trampoline */
+static int sig_verify_ret;
+
+static u8 *s4_verify_digest;
+static struct shash_desc *s4_verify_desc;
+
+int swsusp_prepare_hash(bool may_sleep)
+{
+	struct crypto_shash *tfm;
+	u8 *key;
+	size_t digest_size, desc_size;
+	int ret;
+
+	key = get_efi_secret_key();
+	if (!key) {
+		pr_warn_once("PM: secret key is invalid\n");
+		return -EINVAL;
+	}
+
+	tfm = crypto_alloc_shash(SNAPSHOT_HMAC, 0, 0);
+	if (IS_ERR(tfm)) {
+		pr_err("PM: Allocate HMAC failed: %ld\n", PTR_ERR(tfm));
+		return PTR_ERR(tfm);
+	}
+
+	ret = crypto_shash_setkey(tfm, key, SNAPSHOT_DIGEST_SIZE);
+	if (ret) {
+		pr_err("PM: Set HMAC key failed\n");
+		goto error;
+	}
+
+	desc_size = crypto_shash_descsize(tfm) + sizeof(*s4_verify_desc);
+	digest_size = crypto_shash_digestsize(tfm);
+	s4_verify_digest = kzalloc(digest_size + desc_size, GFP_KERNEL);
+	if (!s4_verify_digest) {
+		pr_err("PM: Allocate digest failed\n");
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	s4_verify_desc = (void *) s4_verify_digest + digest_size;
+	s4_verify_desc->tfm = tfm;
+	ret = crypto_shash_init(s4_verify_desc);
+	if (ret < 0)
+		goto free_shash;
+
+	return 0;
+
+ free_shash:
+	kfree(s4_verify_digest);
+ error:
+	crypto_free_shash(tfm);
+	s4_verify_digest = NULL;
+	s4_verify_desc = NULL;
+	return ret;
+}
+
+void swsusp_finish_hash(void)
+{
+	if (s4_verify_desc)
+		crypto_free_shash(s4_verify_desc->tfm);
+	kfree(s4_verify_digest);
+	s4_verify_desc = NULL;
+	s4_verify_digest = NULL;
+}
+
+int snapshot_image_verify(void)
+{
+	int ret, i;
+
+	if (!h_buf) {
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	if (!efi_enabled(EFI_BOOT)) {
+		pr_info_once("PM: Bypass verification on non-EFI machine\n");
+		ret = 0;
+		goto error_prep;
+	}
+
+	ret = swsusp_prepare_hash(true);
+	if (ret || !s4_verify_desc)
+		goto error_prep;
+
+	for (i = 0; i < (nr_copy_pages + nr_zero_pages); i++) {
+		ret = crypto_shash_update(s4_verify_desc, *(h_buf + i), PAGE_SIZE);
+		if (ret)
+			goto error_shash;
+	}
+
+	ret = crypto_shash_final(s4_verify_desc, s4_verify_digest);
+	if (ret)
+		goto error_shash;
+
+	pr_debug("PM: Signature %*phN\n", SNAPSHOT_DIGEST_SIZE, signature);
+	pr_debug("PM: Digest    %*phN\n", SNAPSHOT_DIGEST_SIZE, s4_verify_digest);
+	if (memcmp(signature, s4_verify_digest, SNAPSHOT_DIGEST_SIZE))
+		ret = -EKEYREJECTED;
+
+ error_shash:
+	swsusp_finish_hash();
+
+ error_prep:
+	vfree(h_buf);
+	if (ret)
+		pr_warn("PM: Signature verification failed: %d\n", ret);
+ error:
+	sig_verify_ret = ret;
+	return ret;
+}
+
+static unsigned long __copy_data_pages(struct memory_bitmap *copy_bm,
 			    struct memory_bitmap *orig_bm,
 			    struct memory_bitmap *zero_bm)
 {
 	unsigned long copied_pages = 0;
-	struct zone *zone;
 	unsigned long pfn, copy_pfn;
+	void *hash_buffer = NULL;
+	struct page *d_page;
+	bool zeros_only;
+	int ret = 0;
 
-	for_each_populated_zone(zone) {
-		unsigned long max_zone_pfn;
-
-		mark_free_pages(zone);
-		max_zone_pfn = zone_end_pfn(zone);
-		for (pfn = zone->zone_start_pfn; pfn < max_zone_pfn; pfn++)
-			if (page_is_saveable(zone, pfn))
-				memory_bm_set_bit(orig_bm, pfn);
+	memory_bm_position_reset(orig_bm);
+	memory_bm_position_reset(copy_bm);
+	copy_pfn = memory_bm_next_pfn(copy_bm);
+	for(;;) {
+		pfn = memory_bm_next_pfn(orig_bm);
+		if (unlikely(pfn == BM_END_OF_MAP))
+			break;
+		zeros_only = copy_data_page(copy_pfn, pfn);
+		/* Update digest */
+		if (s4_verify_desc) {
+			d_page = pfn_to_page(copy_pfn);
+			if (PageHighMem(d_page)) {
+				void *kaddr = kmap_atomic(d_page);
+				copy_page(buffer, kaddr);
+				kunmap_atomic(kaddr);
+				hash_buffer = buffer;
+			} else {
+				hash_buffer = page_address(d_page);
+			}
+			ret = crypto_shash_update(s4_verify_desc, hash_buffer,
+						  PAGE_SIZE);
+			/* return zero copied pages means that we got problem */
+			if (ret)
+				return 0;
+		}
+		if (zeros_only) {
+			memory_bm_set_bit(zero_bm, pfn);
+			/* Use this copy_pfn for a page that is not full of zeros */
+			continue;
+		}
+		copied_pages++;
+		copy_pfn = memory_bm_next_pfn(copy_bm);
+	}
+	if (s4_verify_desc) {
+		ret = crypto_shash_final(s4_verify_desc, s4_verify_digest);
+		if (ret)
+			return 0;
+		memset(signature, 0, SNAPSHOT_DIGEST_SIZE);
+		memcpy(signature, s4_verify_digest, SNAPSHOT_DIGEST_SIZE);
 	}
+	return copied_pages;
+}
+
+static void alloc_h_buf(void)
+{
+	h_buf = vmalloc(sizeof(void *) * (nr_copy_pages + nr_zero_pages));
+	if (h_buf)
+		pr_info("PM: Buffer point array allocated (%d copied pages, %d zero pages)",
+			nr_copy_pages, nr_zero_pages);
+	else
+		pr_err("PM: Allocate buffer point array failed\n");
+}
+
+static void init_signature(struct swsusp_info *info)
+{
+	memcpy(info->signature, signature, SNAPSHOT_DIGEST_SIZE);
+}
+
+static void load_signature(struct swsusp_info *info)
+{
+	memset(signature, 0, SNAPSHOT_DIGEST_SIZE);
+	memcpy(signature, info->signature, SNAPSHOT_DIGEST_SIZE);
+}
+
+static void init_sig_verify(struct trampoline *t)
+{
+	t->sig_verify_ret = sig_verify_ret;
+	sig_verify_ret = 0;
+}
+
+static void handle_sig_verify(struct trampoline *t)
+{
+	if (t->sig_verify_ret)
+		pr_warn("PM: Signature verification failed: %d\n",
+			t->sig_verify_ret);
+	else if (t->secret_key_valid)
+		pr_info("PM: Signature verification passed.\n");
+}
+#else
+static unsigned long __copy_data_pages(struct memory_bitmap *copy_bm,
+			    struct memory_bitmap *orig_bm,
+			    struct memory_bitmap *zero_bm)
+{
+	unsigned long copied_pages = 0;
+	unsigned long pfn, copy_pfn;
+
 	memory_bm_position_reset(orig_bm);
 	memory_bm_position_reset(copy_bm);
 	copy_pfn = memory_bm_next_pfn(copy_bm);
@@ -1582,12 +1787,40 @@ static unsigned long copy_data_pages(str
 	return copied_pages;
 }
 
-/* Total number of image pages */
-static unsigned int nr_copy_pages;
+static inline void alloc_h_buf(void) {}
+static void init_signature(struct swsusp_info *info) {}
+static void load_signature(struct swsusp_info *info) {}
+static void init_sig_verify(struct trampoline *t) {}
+static void handle_sig_verify(struct trampoline *t) {}
+#endif /* CONFIG_HIBERNATE_VERIFICATION */
+
+/*
+ * Copy data pages will copy all pages into pages pulled from the copy_bm.
+ * If a page was entirely filled with zeros it will be marked in the zero_bm.
+ *
+ * Returns the number of pages copied.
+ */
+static unsigned long copy_data_pages(struct memory_bitmap *copy_bm,
+			    struct memory_bitmap *orig_bm,
+			    struct memory_bitmap *zero_bm)
+{
+	struct zone *zone;
+	unsigned long pfn;
+
+	for_each_populated_zone(zone) {
+		unsigned long max_zone_pfn;
+
+		mark_free_pages(zone);
+		max_zone_pfn = zone_end_pfn(zone);
+		for (pfn = zone->zone_start_pfn; pfn < max_zone_pfn; pfn++)
+			if (page_is_saveable(zone, pfn))
+				memory_bm_set_bit(orig_bm, pfn);
+	}
+	return __copy_data_pages(copy_bm, orig_bm, zero_bm);
+}
+
 /* Number of pages needed for saving the original pfns of the image pages */
 static unsigned int nr_meta_pages;
-/* Number of zero pages */
-static unsigned int nr_zero_pages;
 
 /*
  * Numbers of normal and highmem page frames allocated for hibernation image
@@ -2164,6 +2397,12 @@ asmlinkage __visible int swsusp_save(voi
 	 */
 	drain_local_pages(NULL);
 	nr_copy_pages = copy_data_pages(&copy_bm, &orig_bm, &zero_bm);
+	/* It's impossible that the number of copy pages is zero
+	 * Returned a zero value means that the copy_data_pages got problem */
+	if (!nr_copy_pages) {
+		pr_err("PM: Copy data pages failed\n");
+		return -EFAULT;
+	}
 
 	/*
 	 * End of critical section. From now on, we can write to memory,
@@ -2218,6 +2457,7 @@ static int init_header(struct swsusp_inf
 	info->size = info->pages;
 	info->size <<= PAGE_SHIFT;
 	info->trampoline_pfn = page_to_pfn(virt_to_page(trampoline_virt));
+	init_signature(info);
 	return init_header_complete(info);
 }
 
@@ -2266,6 +2506,8 @@ void snapshot_init_trampoline(void)
 	memset(trampoline_buff, 0, PAGE_SIZE);
 	t = (struct trampoline *)trampoline_buff;
 
+	init_sig_verify(t);
+
 	efi_secret_key = get_efi_secret_key();
 	if (efi_secret_key) {
 		memset(t->secret_key, 0, SECRET_KEY_SIZE);
@@ -2293,6 +2535,9 @@ void snapshot_restore_trampoline(void)
 	}
 
 	t = (struct trampoline *)trampoline_virt;
+
+	handle_sig_verify(t);
+
 	if (t->secret_key_valid) {
 		ret = decrypt_restore_hidden_area(t->secret_key, SECRET_KEY_SIZE);
 		if (ret)
@@ -2474,6 +2719,7 @@ static int load_header(struct swsusp_inf
 		nr_copy_pages = info->image_pages;
 		nr_meta_pages = info->pages - info->image_pages - 1;
 		trampoline_pfn = info->trampoline_pfn;
+		load_signature(info);
 	}
 	return error;
 }
@@ -2957,6 +3203,13 @@ next:
 			handle->buffer = get_buffer(&orig_bm, &ca, &pfn);
 			if (IS_ERR(handle->buffer))
 				return PTR_ERR(handle->buffer);
+			/* Allocate buffer point array for generating
+			 * digest to compare with signature.
+			 * h_buf will freed in snapshot_image_verify().
+			 */
+			alloc_h_buf();
+			if (h_buf)
+				*h_buf = handle->buffer;
 		}
 	} else {
 		copy_last_highmem_page();
@@ -2969,6 +3222,8 @@ next:
 		/* Capture the trampoline for transfer data */
 		if (pfn == trampoline_pfn && trampoline_pfn)
 			trampoline_buff = handle->buffer;
+		if (h_buf)
+			*(h_buf + (handle->cur - nr_meta_pages - 1)) = handle->buffer;
 	}
 	handle->sync_read = (handle->buffer == buffer);
 	handle->cur++;
--- a/kernel/power/swap.c
+++ b/kernel/power/swap.c
@@ -1133,7 +1133,8 @@ static int load_image(struct swap_map_ha
 		ret = snapshot_write_finalize(snapshot);
 		if (!ret && !snapshot_image_loaded(snapshot))
 			ret = -ENODATA;
-
+		if (!ret)
+			ret = snapshot_image_verify();
 		snapshot_init_trampoline();
 		/* clean the hidden area in boot kernel */
 		clean_hidden_area();
@@ -1497,6 +1498,8 @@ out_finish:
 				}
 			}
 		}
+		if (!ret)
+			ret = snapshot_image_verify();
 		snapshot_init_trampoline();
 		/* clean the hidden area in boot kernel */
 		clean_hidden_area();
--- a/kernel/power/user.c
+++ b/kernel/power/user.c
@@ -330,6 +330,10 @@ static long snapshot_ioctl(struct file *
 			error = -EPERM;
 			break;
 		}
+		if (snapshot_image_verify()) {
+			error = -EPERM;
+			break;
+		}
 		snapshot_init_trampoline();
 		/* clean the hidden area in boot kernel */
 		clean_hidden_area();
