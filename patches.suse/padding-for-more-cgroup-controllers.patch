From: Michal Koutn√Ω <mkoutny@suse.com>
Date: Mon, 13 Jan 2025 16:15:11 +0100
Subject: padding for more cgroup controllers
Patch-mainline: Never, SUSE-specific
References: jsc#PED-8461

This patch does two things.

First, it extends subsys-holding arrays, so that there are extra slots in
the case we need to add more controllers in the future. This field is
duplicated like O(nr_tasks) but we disabled some v1-only controllers, so we end
up with net zero memory footprint (and fit below 16 constrained by
implementation).

Second, it defines CGROUP_SUBSYS_COUNT_USED that is excluded from KABI and it
is the real bound that those array users should use. Beware, this is brittle
when we backport a new upstream patch that utilizes CGROUP_SUBSYS_COUNT (not
fatal, such functionality would unnecessarily process the extra NULL entry in
SUSE_KABI_CGROUP_SUBSYS_PADDING#).

---
 include/linux/cgroup-defs.h                      |    6 ++++++
 kernel/cgroup/cgroup-internal.h                  |    4 ++--
 kernel/cgroup/cgroup.c                           |   16 ++++++++--------
 tools/testing/selftests/bpf/progs/profiler.inc.h |    2 +-
 4 files changed, 17 insertions(+), 11 deletions(-)

--- a/include/linux/cgroup-defs.h
+++ b/include/linux/cgroup-defs.h
@@ -42,6 +42,12 @@ struct poll_table_struct;
 #define SUBSYS(_x) _x ## _cgrp_id,
 enum cgroup_subsys_id {
 #include <linux/cgroup_subsys.h>
+	SUSE_KABI_CGROUP_SUBSYS_PADDING1,
+#ifndef __GENKSYMS__
+	CGROUP_SUBSYS_COUNT_USED = SUSE_KABI_CGROUP_SUBSYS_PADDING1,
+#endif
+	SUSE_KABI_CGROUP_SUBSYS_PADDING2,
+	SUSE_KABI_CGROUP_SUBSYS_PADDING3,
 	CGROUP_SUBSYS_COUNT,
 };
 #undef SUBSYS
--- a/kernel/cgroup/cgroup-internal.h
+++ b/kernel/cgroup/cgroup-internal.h
@@ -177,10 +177,10 @@ extern struct list_head cgroup_roots;
 /**
  * for_each_subsys - iterate all enabled cgroup subsystems
  * @ss: the iteration cursor
- * @ssid: the index of @ss, CGROUP_SUBSYS_COUNT after reaching the end
+ * @ssid: the index of @ss, CGROUP_SUBSYS_COUNT_USED after reaching the end
  */
 #define for_each_subsys(ss, ssid)					\
-	for ((ssid) = 0; (ssid) < CGROUP_SUBSYS_COUNT &&		\
+	for ((ssid) = 0; (ssid) < CGROUP_SUBSYS_COUNT_USED &&		\
 	     (((ss) = cgroup_subsys[ssid]) || true); (ssid)++)
 
 static inline bool cgroup_is_dead(const struct cgroup *cgrp)
--- a/kernel/cgroup/cgroup.c
+++ b/kernel/cgroup/cgroup.c
@@ -656,13 +656,13 @@ EXPORT_SYMBOL_GPL(of_css);
 /**
  * for_each_css - iterate all css's of a cgroup
  * @css: the iteration cursor
- * @ssid: the index of the subsystem, CGROUP_SUBSYS_COUNT after reaching the end
+ * @ssid: the index of the subsystem, CGROUP_SUBSYS_COUNT_USED after reaching the end
  * @cgrp: the target cgroup to iterate css's of
  *
  * Should be called under cgroup_mutex.
  */
 #define for_each_css(css, ssid, cgrp)					\
-	for ((ssid) = 0; (ssid) < CGROUP_SUBSYS_COUNT; (ssid)++)	\
+	for ((ssid) = 0; (ssid) < CGROUP_SUBSYS_COUNT_USED; (ssid)++)	\
 		if (!((css) = rcu_dereference_check(			\
 				(cgrp)->subsys[(ssid)],			\
 				lockdep_is_held(&cgroup_mutex)))) { }	\
@@ -671,7 +671,7 @@ EXPORT_SYMBOL_GPL(of_css);
 /**
  * do_each_subsys_mask - filter for_each_subsys with a bitmask
  * @ss: the iteration cursor
- * @ssid: the index of @ss, CGROUP_SUBSYS_COUNT after reaching the end
+ * @ssid: the index of @ss, CGROUP_SUBSYS_COUNT_USED after reaching the end
  * @ss_mask: the bitmask
  *
  * The block will only run for cases where the ssid-th bit (1 << ssid) of
@@ -683,7 +683,7 @@ EXPORT_SYMBOL_GPL(of_css);
 		(ssid) = 0;						\
 		break;							\
 	}								\
-	for_each_set_bit(ssid, &__ss_mask, CGROUP_SUBSYS_COUNT) {	\
+	for_each_set_bit(ssid, &__ss_mask, CGROUP_SUBSYS_COUNT_USED) {	\
 		(ss) = cgroup_subsys[ssid];				\
 		{
 
@@ -3422,7 +3422,7 @@ static ssize_t cgroup_subtree_control_wr
 			}
 			break;
 		} while_each_subsys_mask();
-		if (ssid == CGROUP_SUBSYS_COUNT)
+		if (ssid == CGROUP_SUBSYS_COUNT_USED)
 			return -EINVAL;
 	}
 
@@ -3691,7 +3691,7 @@ static int cgroup_stat_show(struct seq_f
 	 * numbers may not be consistent when that happens.
 	 */
 	rcu_read_lock();
-	for (ssid = 0; ssid < CGROUP_SUBSYS_COUNT; ssid++) {
+	for (ssid = 0; ssid < CGROUP_SUBSYS_COUNT_USED; ssid++) {
 		dying_cnt[ssid] = -1;
 		if ((BIT(ssid) & cgrp_dfl_inhibit_ss_mask) ||
 		    (cgroup_subsys[ssid]->root !=  &cgrp_dfl_root))
@@ -3704,7 +3704,7 @@ static int cgroup_stat_show(struct seq_f
 
 	seq_printf(seq, "nr_dying_descendants %d\n",
 		   cgroup->nr_dying_descendants);
-	for (ssid = 0; ssid < CGROUP_SUBSYS_COUNT; ssid++) {
+	for (ssid = 0; ssid < CGROUP_SUBSYS_COUNT_USED; ssid++) {
 		if (dying_cnt[ssid] >= 0)
 			seq_printf(seq, "nr_dying_subsys_%s %d\n",
 				   cgroup_subsys[ssid]->name, dying_cnt[ssid]);
@@ -6164,7 +6164,7 @@ int __init cgroup_init(void)
 	struct cgroup_subsys *ss;
 	int ssid;
 
-	BUILD_BUG_ON(CGROUP_SUBSYS_COUNT > 16);
+	BUILD_BUG_ON(CGROUP_SUBSYS_COUNT_USED > 16);
 	BUG_ON(cgroup_init_cftypes(NULL, cgroup_base_files));
 	BUG_ON(cgroup_init_cftypes(NULL, cgroup_psi_files));
 	BUG_ON(cgroup_init_cftypes(NULL, cgroup1_base_files));
--- a/tools/testing/selftests/bpf/progs/profiler.inc.h
+++ b/tools/testing/selftests/bpf/progs/profiler.inc.h
@@ -261,7 +261,7 @@ static INLINE void* populate_cgroup_info
 #ifdef UNROLL
 		__pragma_loop_unroll
 #endif
-		for (int i = 0; i < CGROUP_SUBSYS_COUNT; i++) {
+		for (int i = 0; i < CGROUP_SUBSYS_COUNT_USED; i++) {
 			struct cgroup_subsys_state* subsys =
 				BPF_CORE_READ(task, cgroups, subsys[i]);
 			if (subsys != NULL) {
