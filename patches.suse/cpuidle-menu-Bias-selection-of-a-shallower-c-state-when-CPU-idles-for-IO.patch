From 9634a9d9726984cc436f610a05abade523c6e88f Mon Sep 17 00:00:00 2001
From: Mel Gorman <mgorman@techsingularity.net>
Date: Tue, 1 Apr 2025 12:56:18 +0100
Subject: [PATCH] cpuidle: menu: Bias selection of a shallower c-state when CPU
 idles for IO

References: bsc#1193353,bsc#1237425
Patch-mainline: Never, likely to be rejected for power vs performance

Originally in SLE15-SP3 it was found that a basic I/O test with FIO doing
large random reads indicated there was a regression relative to older
kernels. The test parameters were

  fio --direct=0 --ioengine=sync --thread --directory=/mnt --invalidate=1
	--group_reporting=1 --runtime=300 --fallocate=posix --ramp_time=10
	--name=RandomReads-128000-32k-4 --new_group --rw=randread
	--size=32000m --numjobs=4 --bs=32k
	--filename_format=FioWorkloads.\$jobnum

Part of the problem is that CPUs fio is running on select the deepest
C-state for short durations. The predicted time to wakeups is not scaled
to the number of IO waiters like interactivity_req and latency_req and
the predictions often suggest an expected idle time far past the next
tick. While this adjusts, it can take a long time as not all idling will
update predictions due to polling or switching.

In SUSE-2025, dbench was found to have a similar problem due to CFS being
replaced by EEVDF and having different behaviour with respect to preempting
current tasks for waking tasks. The heuristics that worked for CFS are
conceptually incompatible with EEVDF.

This patch avoids selecting deep states if there are IO waiters and
stops taking tick being disabled into account when selecting a c-state.

Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 drivers/cpuidle/governors/menu.c | 34 ++++++++++++++++++----------------
 1 file changed, 18 insertions(+), 16 deletions(-)

diff --git a/drivers/cpuidle/governors/menu.c b/drivers/cpuidle/governors/menu.c
index 30ffb1f69056..5de05784da10 100644
--- a/drivers/cpuidle/governors/menu.c
+++ b/drivers/cpuidle/governors/menu.c
@@ -225,6 +225,7 @@ static int menu_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 	struct menu_device *data = this_cpu_ptr(&menu_devices);
 	s64 latency_req = cpuidle_governor_latency_req(dev->cpu);
 	u64 predicted_ns;
+	unsigned int nr_iowaiters;
 	ktime_t delta, delta_tick;
 	int i, idx;
 
@@ -233,6 +234,8 @@ static int menu_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 		data->needs_update = 0;
 	}
 
+	nr_iowaiters = nr_iowait_cpu(dev->cpu);
+
 	/* Find the shortest expected idle interval. */
 	predicted_ns = get_typical_interval(data) * NSEC_PER_USEC;
 	if (predicted_ns > RESIDENCY_THRESHOLD_NS) {
@@ -280,20 +283,8 @@ static int menu_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 		return 0;
 	}
 
-	if (tick_nohz_tick_stopped()) {
-		/*
-		 * If the tick is already stopped, the cost of possible short
-		 * idle duration misprediction is much higher, because the CPU
-		 * may be stuck in a shallow idle state for a long time as a
-		 * result of it.  In that case say we might mispredict and use
-		 * the known time till the closest timer event for the idle
-		 * state selection.
-		 */
-		if (predicted_ns < TICK_NSEC)
-			predicted_ns = data->next_timer_ns;
-	} else if (latency_req > predicted_ns) {
+	if (!tick_nohz_tick_stopped() && latency_req > predicted_ns)
 		latency_req = predicted_ns;
-	}
 
 	/*
 	 * Find the idle state with the lowest power while satisfying
@@ -309,6 +300,12 @@ static int menu_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 		if (idx == -1)
 			idx = i; /* first enabled state */
 
+		/* Use the first non-polling c-state if there are IO waiters. */
+		if (idx >= 0 && nr_iowaiters &&
+		    !(drv->states[idx].flags & CPUIDLE_FLAG_POLLING)) {
+			return idx;
+		}
+
 		if (s->target_residency_ns > predicted_ns) {
 			/*
 			 * Use a physical idle state, not busy polling, unless
@@ -342,8 +339,9 @@ static int menu_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 			 * stuck in the shallow one for too long.
 			 */
 			if (drv->states[idx].target_residency_ns < TICK_NSEC &&
-			    s->target_residency_ns <= delta_tick)
+			    s->target_residency_ns <= delta_tick) {
 				idx = i;
+			}
 
 			return idx;
 		}
@@ -361,10 +359,14 @@ static int menu_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 	 * expected idle duration is shorter than the tick period length.
 	 */
 	if (((drv->states[idx].flags & CPUIDLE_FLAG_POLLING) ||
-	     predicted_ns < TICK_NSEC) && !tick_nohz_tick_stopped()) {
+	     predicted_ns < TICK_NSEC)) {
 		*stop_tick = false;
+		int is_deepest;
+
+		if (drv->states[idx+1].enter == NULL)
+			is_deepest = 1;
 
-		if (idx > 0 && drv->states[idx].target_residency_ns > delta_tick) {
+		if (idx > 0 && (is_deepest || drv->states[idx].target_residency_ns > delta_tick)) {
 			/*
 			 * The tick is not going to be stopped and the target
 			 * residency of the state to be returned is not within
