From 9634a9d9726984cc436f610a05abade523c6e88f Mon Sep 17 00:00:00 2001
From: Mel Gorman <mgorman@techsingularity.net>
Date: Tue, 1 Apr 2025 12:56:18 +0100
Subject: [PATCH] cpuidle: menu: Bias selection of a shallower c-state when CPU
 idles for IO

References: bsc#1193353,bsc#1237425,bsc#1247935)
Patch-mainline: Never, likely to be rejected for power vs performance

Originally in SLE15-SP3 it was found that a basic I/O test with FIO doing
large random reads indicated there was a regression relative to older
kernels. The test parameters were

  fio --direct=0 --ioengine=sync --thread --directory=/mnt --invalidate=1
	--group_reporting=1 --runtime=300 --fallocate=posix --ramp_time=10
	--name=RandomReads-128000-32k-4 --new_group --rw=randread
	--size=32000m --numjobs=4 --bs=32k
	--filename_format=FioWorkloads.\$jobnum

Part of the problem is that CPUs fio is running on select the deepest
C-state for short durations. The predicted time to wakeups is not scaled
to the number of IO waiters like interactivity_req and latency_req and
the predictions often suggest an expected idle time far past the next
tick. While this adjusts, it can take a long time as not all idling will
update predictions due to polling or switching.

In SUSE-2025, dbench was found to have a similar problem due to CFS being
replaced by EEVDF and having different behaviour with respect to preempting
current tasks for waking tasks. The heuristics that worked for CFS are
conceptually incompatible with EEVDF.

This patch avoids selecting deep states if there are IO waiters and
stops taking tick being disabled into account when selecting a c-state.

Signed-off-by: Mel Gorman <mgorman@suse.de>
Signed-off-by: Petr Tesarik <ptesarik@suse.com>
---
 drivers/cpuidle/governors/menu.c |   23 ++++++++++-------------
 1 file changed, 10 insertions(+), 13 deletions(-)

--- a/drivers/cpuidle/governors/menu.c
+++ b/drivers/cpuidle/governors/menu.c
@@ -216,6 +216,7 @@ static int menu_select(struct cpuidle_dr
 	struct menu_device *data = this_cpu_ptr(&menu_devices);
 	s64 latency_req = cpuidle_governor_latency_req(dev->cpu);
 	u64 predicted_ns;
+	unsigned int nr_iowaiters;
 	ktime_t delta, delta_tick;
 	int i, idx;
 
@@ -271,21 +272,12 @@ static int menu_select(struct cpuidle_dr
 		return 0;
 	}
 
-	if (tick_nohz_tick_stopped()) {
-		/*
-		 * If the tick is already stopped, the cost of possible short
-		 * idle duration misprediction is much higher, because the CPU
-		 * may be stuck in a shallow idle state for a long time as a
-		 * result of it.  In that case say we might mispredict and use
-		 * the known time till the closest timer event for the idle
-		 * state selection.
-		 */
-		if (predicted_ns < TICK_NSEC)
-			predicted_ns = data->next_timer_ns;
-	} else if (latency_req > predicted_ns) {
+	if (!tick_nohz_tick_stopped() && latency_req > predicted_ns) {
 		latency_req = predicted_ns;
 	}
 
+	nr_iowaiters = nr_iowait_cpu(dev->cpu);
+
 	/*
 	 * Find the idle state with the lowest power while satisfying
 	 * our constraints.
@@ -341,6 +333,11 @@ static int menu_select(struct cpuidle_dr
 		if (s->exit_latency_ns > latency_req)
 			break;
 
+		/* Use the first non-polling c-state if there are IO waiters. */
+		if (nr_iowaiters &&
+		    !(drv->states[idx].flags & CPUIDLE_FLAG_POLLING))
+			break;
+
 		idx = i;
 	}
 
@@ -352,7 +349,7 @@ static int menu_select(struct cpuidle_dr
 	 * expected idle duration is shorter than the tick period length.
 	 */
 	if (((drv->states[idx].flags & CPUIDLE_FLAG_POLLING) ||
-	     predicted_ns < TICK_NSEC) && !tick_nohz_tick_stopped()) {
+	     predicted_ns < TICK_NSEC)) {
 		*stop_tick = false;
 
 		if (idx > 0 && drv->states[idx].target_residency_ns > delta_tick) {
