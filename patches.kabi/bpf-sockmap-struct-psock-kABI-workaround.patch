From: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Subject: kABI: bpf, sockmap: struct psock related kABI workaround
Patch-mainline: never, kabi
References: bsc#1225475 CVE-2023-52735

Upstream commit d8616ee2affc ("bpf, sockmap: Fix sk->sk_forward_alloc warn_on
in sk_stream_kill_queues") changed struct psock and thus breaks kABI. This can
be workarounded by hiding simply the sock_map_destroy function pointer when generating kernel symbol since struct psock is has a corresponding constructor sk_psock_init().

Separately, upstream commit 8bbabb3fddcd ("bpf, sock_map: Move
cancel_work_sync() out of sock lock") also breaks kABI by changing the
signature of sk_psock_stop() by dropping the `wait` argument. Workaround this
by renaming sk_psock_stop() into sk_psock_stop_new(), and adds a wrapper that
uses the original name and signature that simply call into sk_psock_stop_new(),
then update all in-tree calls to use the new sk_psock_stop_new().

Signed-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
---
 include/linux/bpf.h   |    2 ++
 include/linux/skmsg.h |    7 +++++--
 net/core/skmsg.c      |   10 ++++++++--
 net/core/sock_map.c   |    6 ++++--
 net/ipv4/tcp_bpf.c    |    2 ++
 5 files changed, 21 insertions(+), 6 deletions(-)

--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@ -2190,7 +2190,9 @@ int sock_map_bpf_prog_query(const union
 			    union bpf_attr __user *uattr);
 
 void sock_map_unhash(struct sock *sk);
+#ifndef __GENKSYMS__
 void sock_map_destroy(struct sock *sk);
+#endif /* __GENKSYMS__ */
 void sock_map_close(struct sock *sk, long timeout);
 #else
 static inline int bpf_prog_offload_init(struct bpf_prog *prog,
--- a/include/linux/skmsg.h
+++ b/include/linux/skmsg.h
@@ -95,7 +95,6 @@ struct sk_psock {
 	spinlock_t			link_lock;
 	refcount_t			refcnt;
 	void (*saved_unhash)(struct sock *sk);
-	void (*saved_destroy)(struct sock *sk);
 	void (*saved_close)(struct sock *sk, long timeout);
 	void (*saved_write_space)(struct sock *sk);
 	void (*saved_data_ready)(struct sock *sk);
@@ -106,6 +105,9 @@ struct sk_psock {
 	struct sk_psock_work_state	work_state;
 	struct work_struct		work;
 	struct rcu_work			rwork;
+#ifndef __GENKSYMS__
+	void (*saved_destroy)(struct sock *sk);
+#endif
 };
 
 int sk_msg_alloc(struct sock *sk, struct sk_msg *msg, int len,
@@ -375,7 +377,8 @@ static inline void sk_psock_report_error
 }
 
 struct sk_psock *sk_psock_init(struct sock *sk, int node);
-void sk_psock_stop(struct sk_psock *psock);
+void sk_psock_stop_new(struct sk_psock *psock);
+void sk_psock_stop(struct sk_psock *psock, bool wait);
 
 #if IS_ENABLED(CONFIG_BPF_STREAM_PARSER)
 int sk_psock_init_strp(struct sock *sk, struct sk_psock *psock);
--- a/net/core/skmsg.c
+++ b/net/core/skmsg.c
@@ -720,7 +720,9 @@ struct sk_psock *sk_psock_init(struct so
 	psock->eval = __SK_NONE;
 	psock->sk_proto = prot;
 	psock->saved_unhash = prot->unhash;
+#ifndef __GENKSYMS__
 	psock->saved_destroy = prot->destroy;
+#endif
 	psock->saved_close = prot->close;
 	psock->saved_write_space = sk->sk_write_space;
 
@@ -795,7 +797,7 @@ static void sk_psock_link_destroy(struct
 	}
 }
 
-void sk_psock_stop(struct sk_psock *psock)
+void sk_psock_stop_new(struct sk_psock *psock)
 {
 	spin_lock_bh(&psock->ingress_lock);
 	sk_psock_clear_state(psock, SK_PSOCK_TX_ENABLED);
@@ -804,6 +806,10 @@ void sk_psock_stop(struct sk_psock *psoc
 	spin_unlock_bh(&psock->ingress_lock);
 }
 
+void sk_psock_stop(struct sk_psock *psock, bool wait) {
+	sk_psock_stop_new(psock);
+}
+
 static void sk_psock_done_strp(struct sk_psock *psock);
 
 static void sk_psock_destroy(struct work_struct *work)
@@ -839,7 +845,7 @@ void sk_psock_drop(struct sock *sk, stru
 		sk_psock_stop_verdict(sk, psock);
 	write_unlock_bh(&sk->sk_callback_lock);
 
-	sk_psock_stop(psock);
+	sk_psock_stop_new(psock);
 
 	INIT_RCU_WORK(&psock->rwork, sk_psock_destroy);
 	queue_rcu_work(system_wq, &psock->rwork);
--- a/net/core/sock_map.c
+++ b/net/core/sock_map.c
@@ -1574,6 +1574,7 @@ EXPORT_SYMBOL_GPL(sock_map_unhash);
 
 void sock_map_destroy(struct sock *sk)
 {
+#ifndef __GENKSYMS__
 	void (*saved_destroy)(struct sock *sk);
 	struct sk_psock *psock;
 
@@ -1586,13 +1587,14 @@ void sock_map_destroy(struct sock *sk)
 		saved_destroy = psock->saved_destroy;
 		sock_map_remove_links(sk, psock);
 		rcu_read_unlock();
-		sk_psock_stop(psock);
+		sk_psock_stop_new(psock);
 		sk_psock_put(sk, psock);
 	}
 	if (WARN_ON_ONCE(saved_destroy == sock_map_destroy))
 		return;
 	if (saved_destroy)
 		saved_destroy(sk);
+#endif
 }
 EXPORT_SYMBOL_GPL(sock_map_destroy);
 
@@ -1611,7 +1613,7 @@ void sock_map_close(struct sock *sk, lon
 		if (unlikely(!psock))
 			goto no_psock;
 		rcu_read_unlock();
-		sk_psock_stop(psock);
+		sk_psock_stop_new(psock);
 		release_sock(sk);
 		cancel_work_sync(&psock->work);
 		sk_psock_put(sk, psock);
--- a/net/ipv4/tcp_bpf.c
+++ b/net/ipv4/tcp_bpf.c
@@ -542,7 +542,9 @@ static void tcp_bpf_rebuild_protos(struc
 				   struct proto *base)
 {
 	prot[TCP_BPF_BASE]			= *base;
+#ifndef __GENKSYMS__
 	prot[TCP_BPF_BASE].destroy		= sock_map_destroy;
+#endif
 	prot[TCP_BPF_BASE].close		= sock_map_close;
 	prot[TCP_BPF_BASE].recvmsg		= tcp_bpf_recvmsg;
 	prot[TCP_BPF_BASE].sock_is_readable	= sk_msg_is_readable;
