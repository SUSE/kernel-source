From: Takashi Iwai <tiwai@suse.de>
Subject: kABI workaround for drm_dp_mst helper updates
Patch-mainline: Never, kABI workaround
References: bsc#1206843

Workarounds for kABI breakage due to the recent drm_dp_mst helper
backports:
* Revive dropped field in drm_dp_mst_port, drm_dp_mst_topology_state
  and drm_dp_mst_topology_mgr structs
* The new fields are put either at the hole or at the tail of struct
  with __GENKSYMS__ wrappers
* drm_dp_mst_topology_mgr_init() and drm_dp_mst_atomic_enable_dsc()
  are replaced with new functions
* Some old API functions are still provided but only as dummy
  functions; those spew WARN_ONCE() if actually called

Signed-off-by: Takashi Iwai <tiwai@suse.de>

---
 drivers/gpu/drm/display/drm_dp_mst_topology.c |  107 ++++++++++++++++++++++++++
 include/drm/display/drm_dp_mst_helper.h       |   65 ++++++++++++++-
 2 files changed, 166 insertions(+), 6 deletions(-)

--- a/drivers/gpu/drm/display/drm_dp_mst_topology.c
+++ b/drivers/gpu/drm/display/drm_dp_mst_topology.c
@@ -5459,6 +5459,8 @@ int drm_dp_mst_topology_mgr_init(struct
 	mgr->max_dpcd_transaction_bytes = max_dpcd_transaction_bytes;
 	mgr->max_payloads = max_payloads;
 	mgr->conn_base_id = conn_base_id;
+	/* FIXME: only for kABI compatibility */
+	mutex_init(&mgr->payload_lock);
 
 	mst_state = kzalloc(sizeof(*mst_state), GFP_KERNEL);
 	if (mst_state == NULL)
@@ -5882,3 +5884,108 @@ struct drm_dp_aux *drm_dp_mst_dsc_aux_fo
 	return NULL;
 }
 EXPORT_SYMBOL(drm_dp_mst_dsc_aux_for_port);
+
+/* FIXME: dummy entries for SLE kABI compatibility */
+int drm_dp_find_vcpi_slots(struct drm_dp_mst_topology_mgr *mgr, int pbn)
+{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+	return -ENOSPC;
+}
+EXPORT_SYMBOL(drm_dp_find_vcpi_slots);
+
+int __must_check
+drm_dp_atomic_find_vcpi_slots(struct drm_atomic_state *state,
+			      struct drm_dp_mst_topology_mgr *mgr,
+			      struct drm_dp_mst_port *port, int pbn,
+			      int pbn_div)
+{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+	return -ENOSPC;
+}
+EXPORT_SYMBOL(drm_dp_atomic_find_vcpi_slots);
+
+int __must_check
+drm_dp_atomic_release_vcpi_slots(struct drm_atomic_state *state,
+				 struct drm_dp_mst_topology_mgr *mgr,
+				 struct drm_dp_mst_port *port)
+{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+	return -EINVAL;
+}
+EXPORT_SYMBOL(drm_dp_atomic_release_vcpi_slots);
+
+bool drm_dp_mst_allocate_vcpi(struct drm_dp_mst_topology_mgr *mgr,
+			      struct drm_dp_mst_port *port, int pbn, int slots)
+{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+	return false;
+}
+EXPORT_SYMBOL(drm_dp_mst_allocate_vcpi);
+
+int drm_dp_mst_get_vcpi_slots(struct drm_dp_mst_topology_mgr *mgr,
+			      struct drm_dp_mst_port *port)
+{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+	return 0;
+}
+EXPORT_SYMBOL(drm_dp_mst_get_vcpi_slots);
+
+void drm_dp_mst_reset_vcpi_slots(struct drm_dp_mst_topology_mgr *mgr,
+				 struct drm_dp_mst_port *port)
+{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+}
+EXPORT_SYMBOL(drm_dp_mst_reset_vcpi_slots);
+
+void drm_dp_mst_deallocate_vcpi(struct drm_dp_mst_topology_mgr *mgr,
+				struct drm_dp_mst_port *port)
+{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+}
+EXPORT_SYMBOL(drm_dp_mst_deallocate_vcpi);
+
+int drm_dp_update_payload_part1(struct drm_dp_mst_topology_mgr *mgr,
+				int start_slot)
+{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+	return -ENXIO;
+}
+EXPORT_SYMBOL(drm_dp_update_payload_part1);
+
+int drm_dp_update_payload_part2(struct drm_dp_mst_topology_mgr *mgr)		{
+	WARN_ONCE(1, "%s is deprecated\n", __func__);
+	return -ENXIO;
+}
+EXPORT_SYMBOL(drm_dp_update_payload_part2);
+
+#undef drm_dp_mst_atomic_enable_dsc
+int drm_dp_mst_atomic_enable_dsc(struct drm_atomic_state *state,
+				 struct drm_dp_mst_port *port,
+				 int pbn, int pbn_div,
+				 bool enable)
+{
+	return __drm_dp_mst_atomic_enable_dsc(state, port, pbn, enable);
+}
+EXPORT_SYMBOL(drm_dp_mst_atomic_enable_dsc);
+
+#undef drm_dp_mst_topology_mgr_init
+int drm_dp_mst_topology_mgr_init(struct drm_dp_mst_topology_mgr *mgr,
+				 struct drm_device *dev, struct drm_dp_aux *aux,
+				 int max_dpcd_transaction_bytes, int max_payloads,
+				 int max_lane_count, int max_link_rate,
+				 int conn_base_id)
+{
+	return __drm_dp_mst_topology_mgr_init(mgr, dev, aux,
+					      max_dpcd_transaction_bytes,
+					      max_payloads, conn_base_id);
+}
+EXPORT_SYMBOL(drm_dp_mst_topology_mgr_init);
+
+#undef drm_dp_remove_payload
+void drm_dp_remove_payload(struct drm_dp_mst_topology_mgr *mgr,
+                           struct drm_dp_mst_topology_state *mst_state,
+                           struct drm_dp_mst_atomic_payload *payload)
+{
+	__drm_dp_remove_payload(mgr, mst_state, payload, payload);
+}
+EXPORT_SYMBOL(drm_dp_remove_payload);
--- a/include/drm/display/drm_dp_mst_helper.h
+++ b/include/drm/display/drm_dp_mst_helper.h
@@ -48,6 +48,14 @@ struct drm_dp_mst_topology_ref_history {
 
 struct drm_dp_mst_branch;
 
+/* FIXME: only for SLE15-SP5 kABI compatibility */
+struct drm_dp_vcpi {
+	int vcpi;
+	int pbn;
+	int aligned_pbn;
+	int num_slots;
+};
+
 /**
  * struct drm_dp_mst_port - MST port
  * @port_num: port number
@@ -131,6 +139,7 @@ struct drm_dp_mst_port {
 	struct drm_dp_aux *passthrough_aux;
 	struct drm_dp_mst_branch *parent;
 
+	struct drm_dp_vcpi vcpi;
 	struct drm_connector *connector;
 	struct drm_dp_mst_topology_mgr *mgr;
 
@@ -515,8 +524,29 @@ struct drm_dp_mst_topology_cbs {
 	void (*poll_hpd_irq)(struct drm_dp_mst_topology_mgr *mgr);
 };
 
+#define DP_MAX_PAYLOAD (sizeof(unsigned long) * 8)
+
+#define DP_PAYLOAD_LOCAL 1
+#define DP_PAYLOAD_REMOTE 2
+#define DP_PAYLOAD_DELETE_LOCAL 3
+
+struct drm_dp_payload {
+	int payload_state;
+	int start_slot;
+	int num_slots;
+	int vcpi;
+};
+
 #define to_dp_mst_topology_state(x) container_of(x, struct drm_dp_mst_topology_state, base)
 
+struct drm_dp_vcpi_allocation {
+	struct drm_dp_mst_port *port;
+	int vcpi;
+	int pbn;
+	bool dsc_enabled;
+	struct list_head next;
+};
+
 struct drm_dp_mst_atomic_payload {
 	struct drm_dp_mst_port *port;
 
@@ -566,8 +596,13 @@ struct drm_dp_mst_atomic_payload {
 
 struct drm_dp_mst_topology_state {
 	struct drm_private_state base;
+	struct list_head vcpis;	/* XXX: placeholder for SLE kABI */
 	struct drm_dp_mst_topology_mgr *mgr;
 
+	u8 total_avail_slots;
+	u8 start_slot;
+
+#ifndef __GENKSYMS__
 	/**
 	 * @pending_crtc_mask: A bitmask of all CRTCs this topology state touches, drivers may
 	 * modify this to add additional dependencies if needed.
@@ -586,14 +621,12 @@ struct drm_dp_mst_topology_state {
 	/** @payloads: The list of payloads being created/destroyed in this state */
 	struct list_head payloads;
 
-	u8 total_avail_slots;
-	u8 start_slot;
-
 	/**
 	 * @pbn_div: The current PBN divisor for this topology. The driver is expected to fill this
 	 * out itself.
 	 */
 	int pbn_div;
+#endif /* !__GENKSYMS__ */
 };
 
 #define to_dp_mst_topology_mgr(x) container_of(x, struct drm_dp_mst_topology_mgr, base)
@@ -633,6 +666,11 @@ struct drm_dp_mst_topology_mgr {
 	 * @max_payloads: maximum number of payloads the GPU can generate.
 	 */
 	int max_payloads;
+
+	/* FIXME: placeholders for SLE kABI compatibility */
+	int max_lane_count;
+	int max_link_rate;
+
 	/**
 	 * @conn_base_id: DRM connector ID this mgr is connected to. Only used
 	 * to build the MST connector path value.
@@ -675,6 +713,7 @@ struct drm_dp_mst_topology_mgr {
 	 */
 	bool payload_id_table_cleared : 1;
 
+#ifndef __GENKSYMS__
 	/**
 	 * @payload_count: The number of currently active payloads in hardware. This value is only
 	 * intended to be used internally by MST helpers for payload tracking, and is only safe to
@@ -688,6 +727,7 @@ struct drm_dp_mst_topology_mgr {
 	 * atomic commit (not check) context.
 	 */
 	u8 next_start_slot;
+#endif /* !__GENKSYMS__ */
 
 	/**
 	 * @mst_primary: Pointer to the primary/first branch device.
@@ -703,6 +743,9 @@ struct drm_dp_mst_topology_mgr {
 	 */
 	u8 sink_count;
 
+	/* FIXME: placeholder for SLE kABI */
+	int pbn_div;
+
 	/**
 	 * @funcs: Atomic helper callbacks
 	 */
@@ -718,6 +761,13 @@ struct drm_dp_mst_topology_mgr {
 	 */
 	struct list_head tx_msg_downq;
 
+	/* FIXME: placeholders for SLE kABI */
+	struct mutex payload_lock;
+	struct drm_dp_vcpi **proposed_vcpis;
+	struct drm_dp_payload *payloads;
+	unsigned long payload_mask;
+	unsigned long vcpi_mask;
+
 	/**
 	 * @tx_waitq: Wait to queue stall for the tx worker.
 	 */
@@ -786,10 +836,11 @@ struct drm_dp_mst_topology_mgr {
 #endif
 };
 
-int drm_dp_mst_topology_mgr_init(struct drm_dp_mst_topology_mgr *mgr,
+int __drm_dp_mst_topology_mgr_init(struct drm_dp_mst_topology_mgr *mgr,
 				 struct drm_device *dev, struct drm_dp_aux *aux,
 				 int max_dpcd_transaction_bytes,
 				 int max_payloads, int conn_base_id);
+#define drm_dp_mst_topology_mgr_init __drm_dp_mst_topology_mgr_init
 
 void drm_dp_mst_topology_mgr_destroy(struct drm_dp_mst_topology_mgr *mgr);
 
@@ -820,10 +871,11 @@ int drm_dp_add_payload_part1(struct drm_
 int drm_dp_add_payload_part2(struct drm_dp_mst_topology_mgr *mgr,
 			     struct drm_atomic_state *state,
 			     struct drm_dp_mst_atomic_payload *payload);
-void drm_dp_remove_payload(struct drm_dp_mst_topology_mgr *mgr,
+void __drm_dp_remove_payload(struct drm_dp_mst_topology_mgr *mgr,
 			   struct drm_dp_mst_topology_state *mst_state,
 			   const struct drm_dp_mst_atomic_payload *old_payload,
 			   struct drm_dp_mst_atomic_payload *new_payload);
+#define drm_dp_remove_payload __drm_dp_remove_payload
 
 int drm_dp_check_act_status(struct drm_dp_mst_topology_mgr *mgr);
 
@@ -861,9 +913,10 @@ int __must_check
 drm_dp_atomic_find_time_slots(struct drm_atomic_state *state,
 			      struct drm_dp_mst_topology_mgr *mgr,
 			      struct drm_dp_mst_port *port, int pbn);
-int drm_dp_mst_atomic_enable_dsc(struct drm_atomic_state *state,
+int __drm_dp_mst_atomic_enable_dsc(struct drm_atomic_state *state,
 				 struct drm_dp_mst_port *port,
 				 int pbn, bool enable);
+#define drm_dp_mst_atomic_enable_dsc __drm_dp_mst_atomic_enable_dsc
 int __must_check
 drm_dp_mst_add_affected_dsc_crtcs(struct drm_atomic_state *state,
 				  struct drm_dp_mst_topology_mgr *mgr);
