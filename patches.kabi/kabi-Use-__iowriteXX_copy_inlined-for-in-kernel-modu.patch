From: "Ivan T. Ivanov" <iivanov@suse.de>
Date: Wed, 26 Jun 2024 17:18:38 +0300
Subject: [PATCH] kabi: Use __iowriteXX_copy_inlined for in-kernel modules
Patch-mainline: Never, KABI fix
References: bsc#1226502

Restore __iowriteXX_copy implementation for already build
external partner modules.

Signed-off-by: Ivan T. Ivanov <iivanov@suse.de>
---
 arch/arm64/include/asm/io.h                      |    8 ++++----
 arch/s390/include/asm/io.h                       |    8 ++++----
 arch/s390/pci/pci.c                              |    6 ++++++
 arch/x86/include/asm/io.h                        |    4 ++--
 arch/x86/lib/Makefile                            |    1 +
 arch/x86/lib/iomap_copy_64.S                     |   15 +++++++++++++++
 drivers/cpuidle/cpuidle-qcom-spm.c               |    2 +-
 drivers/infiniband/hw/bnxt_re/qplib_rcfw.c       |    2 +-
 drivers/infiniband/hw/mlx5/mem.c                 |    2 +-
 drivers/mtd/nand/raw/mxc_nand.c                  |    2 +-
 drivers/net/ethernet/amazon/ena/ena_eth_com.c    |    2 +-
 drivers/net/ethernet/broadcom/bnxt/bnxt.c        |    6 +++---
 drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c   |    2 +-
 drivers/net/ethernet/mellanox/mlx4/en_tx.c       |    2 +-
 drivers/net/ethernet/myricom/myri10ge/myri10ge.c |    2 +-
 drivers/net/ethernet/sfc/tx.c                    |    8 ++++----
 drivers/net/wireless/ralink/rt2x00/rt2x00mmio.h  |    2 +-
 drivers/remoteproc/mtk_scp_ipi.c                 |    2 +-
 drivers/rpmsg/qcom_glink_rpm.c                   |    4 ++--
 drivers/rpmsg/qcom_smd.c                         |    2 +-
 drivers/scsi/lpfc/lpfc_compat.h                  |    2 +-
 drivers/slimbus/qcom-ctrl.c                      |    2 +-
 drivers/soc/qcom/qcom_aoss.c                     |    2 +-
 drivers/spi/spi-hisi-sfc-v3xx.c                  |    2 +-
 include/linux/io.h                               |   17 ++++++++++++-----
 lib/iomap_copy.c                                 |   13 +++++++------
 sound/soc/intel/atom/sst/sst_loader.c            |    2 +-
 sound/soc/sof/iomem-utils.c                      |    2 +-
 28 files changed, 77 insertions(+), 47 deletions(-)

--- a/arch/arm64/include/asm/io.h
+++ b/arch/arm64/include/asm/io.h
@@ -219,7 +219,7 @@ __const_memcpy_toio_aligned32(volatile u
 void __iowrite32_copy_full(void __iomem *to, const void *from, size_t count);
 
 static __always_inline void
-__iowrite32_copy(void __iomem *to, const void *from, size_t count)
+__iowrite32_copy_inlined(void __iomem *to, const void *from, size_t count)
 {
 	if (__builtin_constant_p(count) &&
 	    (count == 8 || count == 4 || count == 2 || count == 1)) {
@@ -229,7 +229,7 @@ __iowrite32_copy(void __iomem *to, const
 		__iowrite32_copy_full(to, from, count);
 	}
 }
-#define __iowrite32_copy __iowrite32_copy
+#define __iowrite32_copy_inlined __iowrite32_copy_inlined
 
 static __always_inline void
 __const_memcpy_toio_aligned64(volatile u64 __iomem *to, const u64 *from,
@@ -276,7 +276,7 @@ __const_memcpy_toio_aligned64(volatile u
 void __iowrite64_copy_full(void __iomem *to, const void *from, size_t count);
 
 static __always_inline void
-__iowrite64_copy(void __iomem *to, const void *from, size_t count)
+__iowrite64_copy_inlined(void __iomem *to, const void *from, size_t count)
 {
 	if (__builtin_constant_p(count) &&
 	    (count == 8 || count == 4 || count == 2 || count == 1)) {
@@ -286,7 +286,7 @@ __iowrite64_copy(void __iomem *to, const
 		__iowrite64_copy_full(to, from, count);
 	}
 }
-#define __iowrite64_copy __iowrite64_copy
+#define __iowrite64_copy_inlined __iowrite64_copy_inlined
 
 /*
  * I/O memory mapping functions.
--- a/arch/s390/include/asm/io.h
+++ b/arch/s390/include/asm/io.h
@@ -71,19 +71,19 @@ static inline void ioport_unmap(void __i
 #define __raw_writeq	zpci_write_u64
 
 /* combine single writes by using store-block insn */
-static inline void __iowrite32_copy(void __iomem *to, const void *from,
+static inline void __iowrite32_copy_inlined(void __iomem *to, const void *from,
 				    size_t count)
 {
 	zpci_memcpy_toio(to, from, count * 4);
 }
-#define __iowrite32_copy __iowrite32_copy
+#define __iowrite32_copy_inlined __iowrite32_copy_inlined
 
-static inline void __iowrite64_copy(void __iomem *to, const void *from,
+static inline void __iowrite64_copy_inlined(void __iomem *to, const void *from,
 				    size_t count)
 {
 	zpci_memcpy_toio(to, from, count * 8);
 }
-#define __iowrite64_copy __iowrite64_copy
+#define __iowrite64_copy_inlined __iowrite64_copy_inlined
 
 #endif /* CONFIG_PCI */
 
--- a/arch/s390/pci/pci.c
+++ b/arch/s390/pci/pci.c
@@ -265,6 +265,12 @@ static void __iomem *__ioremap(phys_addr
 	return (void __iomem *) ((unsigned long) area->addr + offset);
 }
 
+/* combine single writes by using store-block insn */
+void __iowrite64_copy(void __iomem *to, const void *from, size_t count)
+{
+       zpci_memcpy_toio(to, from, count * 8);
+}
+
 void __iomem *ioremap_prot(phys_addr_t addr, size_t size, unsigned long prot)
 {
 	return __ioremap(addr, size, __pgprot(prot));
--- a/arch/x86/include/asm/io.h
+++ b/arch/x86/include/asm/io.h
@@ -231,7 +231,7 @@ void memset_io(volatile void __iomem *,
  * x86_64") says that circa 2006 rep movsl is noticeably faster than a copy
  * loop.
  */
-static inline void __iowrite32_copy(void __iomem *to, const void *from,
+static inline void __iowrite32_copy_inlined(void __iomem *to, const void *from,
 				    size_t count)
 {
 	asm volatile("rep ; movsl"
@@ -239,7 +239,7 @@ static inline void __iowrite32_copy(void
 		     : "0"(count), "1"(to), "2"(from)
 		     : "memory");
 }
-#define __iowrite32_copy __iowrite32_copy
+#define __iowrite32_copy_inlined __iowrite32_copy_inlined
 #endif
 
 /*
--- a/arch/x86/lib/Makefile
+++ b/arch/x86/lib/Makefile
@@ -64,6 +64,7 @@ ifneq ($(CONFIG_X86_CMPXCHG64),y)
 endif
         lib-$(CONFIG_X86_USE_3DNOW) += mmx_32.o
 else
+        obj-y += iomap_copy_64.o
         lib-y += csum-partial_64.o csum-copy_64.o csum-wrappers_64.o
         lib-y += clear_page_64.o copy_page_64.o
         lib-y += memmove_64.o memset_64.o
--- /dev/null
+++ b/arch/x86/lib/iomap_copy_64.S
@@ -0,0 +1,15 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/*
+ * Copyright 2006 PathScale, Inc.  All Rights Reserved.
+ */
+
+#include <linux/linkage.h>
+
+/*
+ * override generic version in lib/iomap_copy.c
+ */
+SYM_FUNC_START(__iowrite32_copy)
+	movl %edx,%ecx
+	rep movsl
+	RET
+SYM_FUNC_END(__iowrite32_copy)
\ No newline at end of file
--- a/drivers/cpuidle/cpuidle-qcom-spm.c
+++ b/drivers/cpuidle/cpuidle-qcom-spm.c
@@ -315,7 +315,7 @@ static int spm_dev_probe(struct platform
 
 	/* Write the SPM sequences first.. */
 	addr = drv->reg_base + drv->reg_data->reg_offset[SPM_REG_SEQ_ENTRY];
-	__iowrite32_copy(addr, drv->reg_data->seq,
+	__iowrite32_copy_inlined(addr, drv->reg_data->seq,
 			ARRAY_SIZE(drv->reg_data->seq) / 4);
 
 	/*
--- a/drivers/infiniband/hw/bnxt_re/qplib_rcfw.c
+++ b/drivers/infiniband/hw/bnxt_re/qplib_rcfw.c
@@ -814,7 +814,7 @@ static void bnxt_qplib_start_rcfw(struct
 				    CMDQ_INIT_CMDQ_LVL_MASK));
 	init.creq_ring_id = cpu_to_le16(creq->ring_id);
 	/* Write to the Bono mailbox register */
-	__iowrite32_copy(mbox->reg.bar_reg, &init, sizeof(init) / 4);
+	__iowrite32_copy_inlined(mbox->reg.bar_reg, &init, sizeof(init) / 4);
 }
 
 int bnxt_qplib_enable_rcfw_channel(struct bnxt_qplib_rcfw *rcfw,
--- a/drivers/infiniband/hw/mlx5/mem.c
+++ b/drivers/infiniband/hw/mlx5/mem.c
@@ -148,7 +148,7 @@ static int post_send_nop(struct mlx5_ib_
 	 * we hit doorbell
 	 */
 	wmb();
-	__iowrite64_copy(bf->bfreg->map + bf->offset, mmio_wqe,
+	__iowrite64_copy_inlined(bf->bfreg->map + bf->offset, mmio_wqe,
 			 sizeof(mmio_wqe) / 8);
 
 	bf->offset ^= bf->buf_size;
--- a/drivers/mtd/nand/raw/mxc_nand.c
+++ b/drivers/mtd/nand/raw/mxc_nand.c
@@ -217,7 +217,7 @@ static void memcpy16_fromio(void *trg, c
 static inline void memcpy32_toio(void __iomem *trg, const void *src, int size)
 {
 	/* __iowrite32_copy use 32bit size values so divide by 4 */
-	__iowrite32_copy(trg, src, size / 4);
+	__iowrite32_copy_inlined(trg, src, size / 4);
 }
 
 static void memcpy16_toio(void __iomem *trg, const void *src, int size)
--- a/drivers/net/ethernet/amazon/ena/ena_eth_com.c
+++ b/drivers/net/ethernet/amazon/ena/ena_eth_com.c
@@ -75,7 +75,7 @@ static int ena_com_write_bounce_buffer_t
 	wmb();
 
 	/* The line is completed. Copy it to dev */
-	__iowrite64_copy(io_sq->desc_addr.pbuf_dev_addr + dst_offset,
+	__iowrite64_copy_inlined(io_sq->desc_addr.pbuf_dev_addr + dst_offset,
 			 bounce_buffer, (llq_info->desc_list_entry_size) / 8);
 
 	io_sq->tail++;
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt.c
@@ -496,11 +496,11 @@ static netdev_tx_t bnxt_start_xmit(struc
 
 		push_len = (length + sizeof(*tx_push) + 7) / 8;
 		if (push_len > 16) {
-			__iowrite64_copy(db, tx_push_buf, 16);
-			__iowrite32_copy(db + 4, tx_push_buf + 1,
+			__iowrite64_copy_inlined(db, tx_push_buf, 16);
+			__iowrite32_copy_inlined(db + 4, tx_push_buf + 1,
 					 (push_len - 16) << 1);
 		} else {
-			__iowrite64_copy(db, tx_push_buf, push_len);
+			__iowrite64_copy_inlined(db, tx_push_buf, push_len);
 		}
 
 		goto tx_done;
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c
@@ -526,7 +526,7 @@ static int __hwrm_send(struct bnxt *bp,
 	wmb();
 
 	/* Write request msg to hwrm channel */
-	__iowrite32_copy(bp->bar0 + bar_offset, data, msg_len / 4);
+	__iowrite32_copy_inlined(bp->bar0 + bar_offset, data, msg_len / 4);
 
 	for (i = msg_len; i < max_req_len; i += 4)
 		writel(0, bp->bar0 + bar_offset + i);
--- a/drivers/net/ethernet/mellanox/mlx4/en_tx.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_tx.c
@@ -737,7 +737,7 @@ u16 mlx4_en_select_queue(struct net_devi
 static void mlx4_bf_copy(void __iomem *dst, const void *src,
 			 unsigned int bytecnt)
 {
-	__iowrite64_copy(dst, src, bytecnt / 8);
+	__iowrite64_copy_inlined(dst, src, bytecnt / 8);
 }
 
 void mlx4_en_xmit_doorbell(struct mlx4_en_tx_ring *ring)
--- a/drivers/net/ethernet/myricom/myri10ge/myri10ge.c
+++ b/drivers/net/ethernet/myricom/myri10ge/myri10ge.c
@@ -351,7 +351,7 @@ MODULE_PARM_DESC(myri10ge_dca, "Enable D
 (sizeof (X) == 8) ? ((u32)((u64)(X) >> 32)) : (0)
 #define MYRI10GE_LOWPART_TO_U32(X) ((u32)(X))
 
-#define myri10ge_pio_copy(to,from,size) __iowrite64_copy(to,from,size/8)
+#define myri10ge_pio_copy(to,from,size) __iowrite64_copy_inlined(to,from,size/8)
 
 static void myri10ge_set_multicast_list(struct net_device *dev);
 static netdev_tx_t myri10ge_sw_tso(struct sk_buff *skb,
--- a/drivers/net/ethernet/sfc/tx.c
+++ b/drivers/net/ethernet/sfc/tx.c
@@ -139,7 +139,7 @@ static void efx_memcpy_toio_aligned(stru
 {
 	int block_len = len & ~(sizeof(copy_buf->buf) - 1);
 
-	__iowrite64_copy(*piobuf, data, block_len >> 3);
+	__iowrite64_copy_inlined(*piobuf, data, block_len >> 3);
 	*piobuf += block_len;
 	len -= block_len;
 
@@ -171,7 +171,7 @@ static void efx_memcpy_toio_aligned_cb(s
 		if (copy_buf->used < sizeof(copy_buf->buf))
 			return;
 
-		__iowrite64_copy(*piobuf, copy_buf->buf,
+		__iowrite64_copy_inlined(*piobuf, copy_buf->buf,
 				 sizeof(copy_buf->buf) >> 3);
 		*piobuf += sizeof(copy_buf->buf);
 		data += copy_to_buf;
@@ -187,7 +187,7 @@ static void efx_flush_copy_buffer(struct
 {
 	/* if there's anything in it, write the whole buffer, including junk */
 	if (copy_buf->used)
-		__iowrite64_copy(piobuf, copy_buf->buf,
+		__iowrite64_copy_inlined(piobuf, copy_buf->buf,
 				 sizeof(copy_buf->buf) >> 3);
 }
 
@@ -247,7 +247,7 @@ static int efx_enqueue_skb_pio(struct ef
 		 */
 		BUILD_BUG_ON(L1_CACHE_BYTES >
 			     SKB_DATA_ALIGN(sizeof(struct skb_shared_info)));
-		__iowrite64_copy(tx_queue->piobuf, skb->data,
+		__iowrite64_copy_inlined(tx_queue->piobuf, skb->data,
 				 ALIGN(skb->len, L1_CACHE_BYTES) >> 3);
 	}
 
--- a/drivers/net/wireless/ralink/rt2x00/rt2x00mmio.h
+++ b/drivers/net/wireless/ralink/rt2x00/rt2x00mmio.h
@@ -43,7 +43,7 @@ static inline void rt2x00mmio_register_m
 						  const void *value,
 						  const u32 length)
 {
-	__iowrite32_copy(rt2x00dev->csr.base + offset, value, length >> 2);
+	__iowrite32_copy_inlined(rt2x00dev->csr.base + offset, value, length >> 2);
 }
 
 /**
--- a/drivers/remoteproc/mtk_scp_ipi.c
+++ b/drivers/remoteproc/mtk_scp_ipi.c
@@ -93,7 +93,7 @@ void scp_memcpy_aligned(void __iomem *ds
 		writel_relaxed(val, ptr);
 	}
 
-	__iowrite32_copy(dst + i, src + i, (len - i) / 4);
+	__iowrite32_copy_inlined(dst + i, src + i, (len - i) / 4);
 	remain = (len - i) % 4;
 
 	if (remain > 0) {
--- a/drivers/rpmsg/qcom_glink_rpm.c
+++ b/drivers/rpmsg/qcom_glink_rpm.c
@@ -130,12 +130,12 @@ static unsigned int glink_rpm_tx_write_o
 
 	len = min_t(size_t, count, pipe->native.length - head);
 	if (len) {
-		__iowrite32_copy(pipe->fifo + head, data,
+		__iowrite32_copy_inlined(pipe->fifo + head, data,
 				 len / sizeof(u32));
 	}
 
 	if (len != count) {
-		__iowrite32_copy(pipe->fifo, data + len,
+		__iowrite32_copy_inlined(pipe->fifo, data + len,
 				 (count - len) / sizeof(u32));
 	}
 
--- a/drivers/rpmsg/qcom_smd.c
+++ b/drivers/rpmsg/qcom_smd.c
@@ -469,7 +469,7 @@ static void smd_copy_to_fifo(void __iome
 			     bool word_aligned)
 {
 	if (word_aligned) {
-		__iowrite32_copy(dst, src, count / sizeof(u32));
+		__iowrite32_copy_inlined(dst, src, count / sizeof(u32));
 	} else {
 		memcpy_toio(dst, src, count);
 	}
--- a/drivers/scsi/lpfc/lpfc_compat.h
+++ b/drivers/scsi/lpfc/lpfc_compat.h
@@ -85,7 +85,7 @@ static inline void
 lpfc_memcpy_to_slim( void __iomem *dest, void *src, unsigned int bytes)
 {
 	/* convert bytes in argument list to word count for copy function */
-	__iowrite32_copy(dest, src, bytes / sizeof(uint32_t));
+	__iowrite32_copy_inlined(dest, src, bytes / sizeof(uint32_t));
 }
 
 static inline void
--- a/drivers/slimbus/qcom-ctrl.c
+++ b/drivers/slimbus/qcom-ctrl.c
@@ -122,7 +122,7 @@ static void qcom_slim_queue_tx(struct qc
 {
 	int count = (len + 3) >> 2;
 
-	__iowrite32_copy(ctrl->base + tx_reg, buf, count);
+	__iowrite32_copy_inlined(ctrl->base + tx_reg, buf, count);
 
 	/* Ensure Oder of subsequent writes */
 	mb();
--- a/drivers/soc/qcom/qcom_aoss.c
+++ b/drivers/soc/qcom/qcom_aoss.c
@@ -242,7 +242,7 @@ int qmp_send(struct qmp *qmp, const void
 	mutex_lock(&qmp->tx_lock);
 
 	/* The message RAM only implements 32-bit accesses */
-	__iowrite32_copy(qmp->msgram + qmp->offset + sizeof(u32),
+	__iowrite32_copy_inlined(qmp->msgram + qmp->offset + sizeof(u32),
 			 data, len / sizeof(u32));
 	writel(len, qmp->msgram + qmp->offset);
 
--- a/drivers/spi/spi-hisi-sfc-v3xx.c
+++ b/drivers/spi/spi-hisi-sfc-v3xx.c
@@ -243,7 +243,7 @@ static void hisi_sfc_v3xx_write_databuf(
 	if (IS_ALIGNED((uintptr_t)from, 4)) {
 		int words = len / 4;
 
-		__iowrite32_copy(to, from, words);
+		__iowrite32_copy_inlined(to, from, words);
 
 		len -= words * 4;
 		if (len) {
--- a/include/linux/io.h
+++ b/include/linux/io.h
@@ -16,14 +16,21 @@
 struct device;
 struct resource;
 
-#ifndef __iowrite32_copy
-void __iowrite32_copy(void __iomem *to, const void *from, size_t count);
+__visible void __iowrite32_copy(void __iomem *to, const void *from, size_t count);
+void __ioread32_copy(void *to, const void __iomem *from, size_t count);
+void __iowrite64_copy(void __iomem *to, const void *from, size_t count);
+
+#ifndef __GENKSYMS__
+
+/* Fallback */
+#ifndef __iowrite32_copy_inlined
+#define __iowrite32_copy_inlined __iowrite32_copy
 #endif
 
-void __ioread32_copy(void *to, const void __iomem *from, size_t count);
+#ifndef __iowrite64_copy_inlined
+#define __iowrite64_copy_inlined __iowrite64_copy
+#endif
 
-#ifndef __iowrite64_copy
-void __iowrite64_copy(void __iomem *to, const void *from, size_t count);
 #endif
 
 #ifdef CONFIG_MMU
--- a/lib/iomap_copy.c
+++ b/lib/iomap_copy.c
@@ -16,8 +16,9 @@
  * time.  Order of access is not guaranteed, nor is a memory barrier
  * performed afterwards.
  */
-#ifndef __iowrite32_copy
-void __iowrite32_copy(void __iomem *to, const void *from, size_t count)
+void __attribute__((weak)) __iowrite32_copy(void __iomem *to,
+					    const void *from,
+					    size_t count)
 {
 	u32 __iomem *dst = to;
 	const u32 *src = from;
@@ -27,7 +28,6 @@ void __iowrite32_copy(void __iomem *to,
 		__raw_writel(*src++, dst++);
 }
 EXPORT_SYMBOL_GPL(__iowrite32_copy);
-#endif
 
 /**
  * __ioread32_copy - copy data from MMIO space, in 32-bit units
@@ -60,8 +60,9 @@ EXPORT_SYMBOL_GPL(__ioread32_copy);
  * time.  Order of access is not guaranteed, nor is a memory barrier
  * performed afterwards.
  */
-#ifndef __iowrite64_copy
-void __iowrite64_copy(void __iomem *to, const void *from, size_t count)
+void __attribute__((weak)) __iowrite64_copy(void __iomem *to,
+					    const void *from,
+					    size_t count)
 {
 #ifdef CONFIG_64BIT
 	u64 __iomem *dst = to;
@@ -74,5 +75,5 @@ void __iowrite64_copy(void __iomem *to,
 	__iowrite32_copy(to, from, count * 2);
 #endif
 }
+
 EXPORT_SYMBOL_GPL(__iowrite64_copy);
-#endif
--- a/sound/soc/intel/atom/sst/sst_loader.c
+++ b/sound/soc/intel/atom/sst/sst_loader.c
@@ -35,7 +35,7 @@ void memcpy32_toio(void __iomem *dst, co
 	/* __iowrite32_copy uses 32-bit count values so divide by 4 for
 	 * right count in words
 	 */
-	__iowrite32_copy(dst, src, count / 4);
+	__iowrite32_copy_inlined(dst, src, count / 4);
 }
 
 void memcpy32_fromio(void *dst, const void __iomem *src, int count)
--- a/sound/soc/sof/iomem-utils.c
+++ b/sound/soc/sof/iomem-utils.c
@@ -92,7 +92,7 @@ int sof_block_write(struct snd_sof_dev *
 	n = size % 4;
 
 	/* __iowrite32_copy use 32bit size values so divide by 4 */
-	__iowrite32_copy(dest, src, m);
+	__iowrite32_copy_inlined(dest, src, m);
 
 	if (n) {
 		affected_mask = (1 << (8 * n)) - 1;
