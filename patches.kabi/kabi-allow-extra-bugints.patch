From: Nikolay Borisov <bp@alien8.de>
Date: Tue, 22 Aug 2023 13:53:41 +0200
Subject: kabi: Allow extra bugsints
Patch-mainline: Never, kabi fix
References: bsc#1213927

Since cpuinfo_x86 cannot be grown because of kABI consideration implement a scheme
which allows to add new caps bit. The idea is to simply add a new x86_ext_capability
array at the end of cpuinfo_x86 thus retaining kABI. All new cpuid bits will Subsequently
be recorded in the new member.

Additionally cpu_caps_set is also grown by the number of additional cpuid words
and the getter/setter macros are modified to reflect this. All forced bits which
belong to extended cpuid words will be written in cpu_caps_set after NCAPINTS+NBUGINTS.

In this implementation, the features/bugs word/bit ordering is as follows.

In struct cpuinfo_x86:
NCAPINTS, NBUGINTS (in .x86_capability|])
NEXTCAPINTS, NEXTBUGINTS (in .x86_ext_capability[])

In cpu_caps_set[];
NCAPINTS, NBUGINTS, NEXTCAPINTS, NEXTBUGINTS

For boot_cpu_has_bug() etc.:
NCAPINTS, NBUGINTS, NEXTCAPINTS, NEXTBUGINTS

This preserves the value of the X86_FEATURE_* and X86_BUG_* flags which were
defined in the GA version of SLE15-SP5 kernel. Extended flags are not
preserved.

Signed-off-by: Nikolay Borisov  <nik.borisov@suse.com>
---
 arch/x86/include/asm/cpufeature.h  |   43 ++++++++++++++++++++++++++-----------
 arch/x86/include/asm/cpufeatures.h |   27 ++++++++++++++---------
 arch/x86/include/asm/processor.h   |    7 +++++-
 arch/x86/kernel/alternative.c      |    2 -
 arch/x86/kernel/cpu/common.c       |   18 +++++++++++++--
 arch/x86/kernel/cpu/mkcapflags.sh  |   17 +++++---------
 arch/x86/kernel/cpu/proc.c         |   12 ++++++++++
 arch/x86/net/bpf_jit_comp.c        |    6 ++---
 8 files changed, 92 insertions(+), 40 deletions(-)

--- a/arch/x86/include/asm/cpufeature.h
+++ b/arch/x86/include/asm/cpufeature.h
@@ -34,11 +34,19 @@ enum cpuid_leafs
 	CPUID_8000_001F_EAX,
 	CPUID_8000_0021_EAX,
 	CPUID_LNX_5,
+	CPUID_MAX = CPUID_LNX_5,
+	/*
+	 * Everything below should go into the extended caps array to preserve
+	 * kABI
+	 */
 	CPUID_LNX_6,
 };
 
+#define CPUID_IDX(x) ((x) - CPUID_MAX - 1)
+#define IS_EXT_BIT(bit) ((bit>>5) >= (NCAPINTS + NBUGINTS))
+
 #ifdef CONFIG_X86_FEATURE_NAMES
-extern const char * const x86_cap_flags[NCAPINTS*32];
+extern const char * const x86_cap_flags[(NCAPINTS+NEXTCAPINTS)*32];
 extern const char * const x86_power_flags[32];
 #define X86_CAP_FMT "%s"
 #define x86_cap_flag(flag) x86_cap_flags[flag]
@@ -49,12 +57,14 @@ extern const char * const x86_power_flag
 
 /*
  * In order to save room, we index into this array by doing
- * X86_BUG_<name> - NCAPINTS*32.
+ * X86_BUGINDEX(X86_BUG_<name>).
  */
-extern const char * const x86_bug_flags[NBUGINTS*32];
+extern const char * const x86_bug_flags[(NBUGINTS+NEXTBUGINTS)*32];
 
 #define test_cpu_cap(c, bit)						\
-	 test_bit(bit, (unsigned long *)((c)->x86_capability))
+ (IS_EXT_BIT(bit) ? test_bit((bit) - (NCAPINTS+NBUGINTS)*32,		\
+			     (unsigned long *)((c)->x86_ext_capability)) : \
+		    test_bit(bit, (unsigned long *)((c)->x86_capability)))
 
 /*
  * There are 32 bits/features in each mask word.  The high bits
@@ -129,8 +139,9 @@ extern const char * const x86_bug_flags[
 
 #define this_cpu_has(bit)						\
 	(__builtin_constant_p(bit) && REQUIRED_MASK_BIT_SET(bit) ? 1 :	\
-	 x86_this_cpu_test_bit(bit,					\
-		(unsigned long __percpu *)&cpu_info.x86_capability))
+	 (IS_EXT_BIT(bit) ? x86_this_cpu_test_bit((bit) - (NCAPINTS+NBUGINTS)*32, \
+						  (unsigned long *)&cpu_info.x86_ext_capability) : \
+	  x86_this_cpu_test_bit(bit, (unsigned long *)&cpu_info.x86_capability)))
 
 /*
  * This macro is for detection of features which need kernel
@@ -145,7 +156,14 @@ extern const char * const x86_bug_flags[
 
 #define boot_cpu_has(bit)	cpu_has(&boot_cpu_data, bit)
 
-#define set_cpu_cap(c, bit)	set_bit(bit, (unsigned long *)((c)->x86_capability))
+#define set_cpu_cap(c, bit) do {					\
+	if (IS_EXT_BIT(bit)) {						\
+		set_bit((bit) - (NCAPINTS+NBUGINTS)*32,			\
+			(unsigned long *)(c)->x86_ext_capability);	\
+	} else {							\
+		set_bit(bit, (unsigned long *)((c)->x86_capability));	\
+	}								\
+} while (0)
 
 extern void setup_clear_cpu_cap(unsigned int bit);
 extern void clear_cpu_cap(struct cpuinfo_x86 *c, unsigned int bit);
@@ -200,11 +218,12 @@ t_no:
 }
 
 #define static_cpu_has(bit)					\
-(								\
-	__builtin_constant_p(boot_cpu_has(bit)) ?		\
+({								\
+	BUILD_BUG_ON_MSG(IS_EXT_BIT(bit), "extended bits/bugs not supported"); \
+	(__builtin_constant_p(boot_cpu_has(bit)) ?		\
 		boot_cpu_has(bit) :				\
-		_static_cpu_has(bit)				\
-)
+		_static_cpu_has(bit));				\
+})
 #endif
 
 #define cpu_has_bug(c, bit)		cpu_has(c, (bit))
@@ -215,7 +234,7 @@ t_no:
 #define boot_cpu_has_bug(bit)		cpu_has_bug(&boot_cpu_data, (bit))
 #define boot_cpu_set_bug(bit)		set_cpu_cap(&boot_cpu_data, (bit))
 
-#define MAX_CPU_FEATURES		(NCAPINTS * 32)
+#define MAX_CPU_FEATURES		((NCAPINTS + NEXTCAPINTS)*32)
 #define cpu_have_feature		boot_cpu_has
 
 #define CPU_FEATURE_TYPEFMT		"x86,ven%04Xfam%04Xmod%04X"
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@ -16,6 +16,8 @@
 #define NCAPINTS			22	   /* N 32-bit words worth of info */
 #define NBUGINTS			1	   /* N 32-bit bug flags */
 
+#define NEXTCAPINTS			1
+#define NEXTBUGINTS			1
 /*
  * Note: If the comment begins with a quoted string, that string is used
  * in /proc/cpuinfo instead of the macro name.  If the string is "",
@@ -441,16 +443,21 @@
 
 #define X86_FEATURE_INDIRECT_THUNK_ITS	(21*32 + 9) /* Use thunk for indirect branches in lower half of cacheline */
 
+#define X86_EXT_FEATURE(x)		(NBUGINTS*32 + (x))
+#define X86_FEATUREINDEX(x)		((x) < NCAPINTS*32 ? (x) : (x) - NBUGINTS*32)
+
 /* Linux defined features */
-#define X86_FEATURE_CLEAR_BHB_LOOP	(22*32+ 0) /* "" Clear branch history at syscall entry using SW loop */
-#define X86_FEATURE_BHI_CTRL		(22*32+ 1) /* "" BHI_DIS_S HW control available */
-#define X86_FEATURE_CLEAR_BHB_HW	(22*32+ 2) /* "" BHI_DIS_S HW control enabled */
-#define X86_FEATURE_CLEAR_BHB_LOOP_ON_VMEXIT (22*32+ 3) /* "" Clear branch history at vmexit using SW loop */
+#define X86_FEATURE_CLEAR_BHB_LOOP	X86_EXT_FEATURE(22*32+ 0) /* "" Clear branch history at syscall entry using SW loop */
+#define X86_FEATURE_BHI_CTRL		X86_EXT_FEATURE(22*32+ 1) /* "" BHI_DIS_S HW control available */
+#define X86_FEATURE_CLEAR_BHB_HW	X86_EXT_FEATURE(22*32+ 2) /* "" BHI_DIS_S HW control enabled */
+#define X86_FEATURE_CLEAR_BHB_LOOP_ON_VMEXIT X86_EXT_FEATURE(22*32+ 3) /* "" Clear branch history at vmexit using SW loop */
 
 /*
  * BUG word(s)
  */
 #define X86_BUG(x)			(NCAPINTS*32 + (x))
+#define X86_EXT_BUG(x)			((NCAPINTS+NEXTCAPINTS)*32 + (x))
+#define X86_BUGINDEX(x)			((x) < (NCAPINTS+NBUGINTS)*32 ? (x) - NCAPINTS*32 : (x) - (NCAPINTS+NEXTCAPINTS)*32)
 
 #define X86_BUG_F00F			X86_BUG(0) /* Intel F00F */
 #define X86_BUG_FDIV			X86_BUG(1) /* FPU FDIV */
@@ -492,10 +499,10 @@
 #define X86_BUG_GDS			X86_BUG(31) /* CPU is affected by Gather Data Sampling */
 
 /* BUG word 2 */
-#define X86_BUG_DIV0			X86_BUG(1*32 + 0) /* AMD DIV0 speculation bug */
-#define X86_BUG_RFDS			X86_BUG(1*32 + 1) /* CPU is vulnerable to Register File Data Sampling */
-#define X86_BUG_BHI			X86_BUG(1*32 + 2) /* CPU is affected by Branch History Injection */
-#define X86_BUG_IBPB_NO_RET		X86_BUG(1*32 + 4) /* "ibpb_no_ret" IBPB omits return target predictions */
-#define X86_BUG_ITS			X86_BUG(1*32 + 6) /* "its" CPU is affected by Indirect Target Selection */
-#define X86_BUG_ITS_NATIVE_ONLY		X86_BUG(1*32 + 7) /* "its_native_only" CPU is affected by ITS, VMX is not affected */
+#define X86_BUG_DIV0			X86_EXT_BUG(1*32 + 0) /* AMD DIV0 speculation bug */
+#define X86_BUG_RFDS			X86_EXT_BUG(1*32 + 1) /* CPU is vulnerable to Register File Data Sampling */
+#define X86_BUG_BHI			X86_EXT_BUG(1*32 + 2) /* CPU is affected by Branch History Injection */
+#define X86_BUG_IBPB_NO_RET		X86_EXT_BUG(1*32 + 4) /* "ibpb_no_ret" IBPB omits return target predictions */
+#define X86_BUG_ITS			X86_EXT_BUG(1*32 + 6) /* "its" CPU is affected by Indirect Target Selection */
+#define X86_BUG_ITS_NATIVE_ONLY		X86_EXT_BUG(1*32 + 7) /* "its_native_only" CPU is affected by ITS, VMX is not affected */
 #endif /* _ASM_X86_CPUFEATURES_H */
--- a/arch/x86/include/asm/processor.h
+++ b/arch/x86/include/asm/processor.h
@@ -143,6 +143,11 @@ struct cpuinfo_x86 {
 #ifndef __GENKSYMS__
 	/* protected processor identification number */
 	u64			ppin;
+	union {
+		__u32		x86_ext_capability[NEXTCAPINTS+NEXTBUGINTS];
+		unsigned long	x86_ext_capability_alignemnt;
+	};
+
 #endif
 } __randomize_layout;
 
@@ -177,7 +182,7 @@ extern struct cpuinfo_x86	boot_cpu_data;
 extern struct cpuinfo_x86	new_cpu_data;
 
 extern __u32			cpu_caps_cleared[NCAPINTS + NBUGINTS];
-extern __u32			cpu_caps_set[NCAPINTS + NBUGINTS];
+extern __u32			cpu_caps_set[NCAPINTS + NBUGINTS + NEXTCAPINTS + NEXTBUGINTS];
 
 #ifdef CONFIG_SMP
 DECLARE_PER_CPU_READ_MOSTLY(struct cpuinfo_x86, cpu_info);
--- a/arch/x86/kernel/alternative.c
+++ b/arch/x86/kernel/alternative.c
@@ -524,7 +524,7 @@ void __init_or_module noinline apply_alt
 		instr = (u8 *)&a->instr_offset + a->instr_offset;
 		replacement = (u8 *)&a->repl_offset + a->repl_offset;
 		BUG_ON(a->instrlen > sizeof(insn_buff));
-		BUG_ON(feature >= (NCAPINTS + NBUGINTS) * 32);
+		BUG_ON(feature >= (NCAPINTS + NBUGINTS + NEXTCAPINTS + NEXTBUGINTS) * 32);
 
 		/*
 		 * Patch if either:
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@ -678,7 +678,7 @@ static const char *table_lookup_model(st
 
 /* Aligned to unsigned long to avoid split lock in atomic bitmap ops */
 __u32 cpu_caps_cleared[NCAPINTS + NBUGINTS] __aligned(sizeof(unsigned long));
-__u32 cpu_caps_set[NCAPINTS + NBUGINTS] __aligned(sizeof(unsigned long));
+__u32 cpu_caps_set[NCAPINTS + NBUGINTS + NEXTCAPINTS + NEXTBUGINTS] __aligned(sizeof(unsigned long));
 
 void load_percpu_segment(int cpu)
 {
@@ -940,6 +940,10 @@ static void apply_forced_caps(struct cpu
 		c->x86_capability[i] &= ~cpu_caps_cleared[i];
 		c->x86_capability[i] |= cpu_caps_set[i];
 	}
+
+	for (i = 0; i < NEXTCAPINTS + NEXTBUGINTS; i++) {
+		c->x86_ext_capability[i] |= cpu_caps_set[NCAPINTS+NBUGINTS + i];
+	}
 }
 
 static void init_speculation_control(struct cpuinfo_x86 *c)
@@ -1591,6 +1595,7 @@ static void __init early_identify_cpu(st
 	c->x86_cache_alignment = c->x86_clflush_size;
 
 	memset(&c->x86_capability, 0, sizeof(c->x86_capability));
+	memset(&c->x86_ext_capability, 0, sizeof(c->x86_ext_capability));
 	c->extended_cpuid_level = 0;
 
 	if (!have_cpuid_p())
@@ -1848,6 +1853,7 @@ static void identify_cpu(struct cpuinfo_
 #endif
 	c->x86_cache_alignment = c->x86_clflush_size;
 	memset(&c->x86_capability, 0, sizeof(c->x86_capability));
+	memset(&c->x86_ext_capability, 0, sizeof(c->x86_ext_capability));
 #ifdef CONFIG_X86_VMX_FEATURE_NAMES
 	memset(&c->vmx_capability, 0, sizeof(c->vmx_capability));
 #endif
@@ -1934,10 +1940,14 @@ static void identify_cpu(struct cpuinfo_
 		/* AND the already accumulated flags with these */
 		for (i = 0; i < NCAPINTS; i++)
 			boot_cpu_data.x86_capability[i] &= c->x86_capability[i];
+		for (i = 0; i < NEXTCAPINTS; i++)
+			boot_cpu_data.x86_ext_capability[i] &= c->x86_ext_capability[i];
 
 		/* OR, i.e. replicate the bug flags */
 		for (i = NCAPINTS; i < NCAPINTS + NBUGINTS; i++)
 			c->x86_capability[i] |= boot_cpu_data.x86_capability[i];
+		for (i = NEXTCAPINTS; i < NEXTCAPINTS + NEXTBUGINTS; i++)
+			c->x86_ext_capability[i] |= boot_cpu_data.x86_ext_capability[i];
 	}
 
 	ppin_init(c);
@@ -2383,6 +2393,8 @@ void store_cpu_caps(struct cpuinfo_x86 *
 	/* Copy all capability leafs and pick up the synthetic ones. */
 	memcpy(&curr_info->x86_capability, &boot_cpu_data.x86_capability,
 	       sizeof(curr_info->x86_capability));
+	memcpy(&curr_info->x86_ext_capability, &boot_cpu_data.x86_ext_capability,
+	       sizeof(curr_info->x86_ext_capability));
 
 	/* Get the hardware CPUID leafs */
 	get_cpu_cap(curr_info);
@@ -2409,7 +2421,9 @@ void microcode_check(struct cpuinfo_x86
 	store_cpu_caps(&curr_info);
 
 	if (!memcmp(&prev_info->x86_capability, &curr_info.x86_capability,
-		    sizeof(prev_info->x86_capability)))
+		    sizeof(prev_info->x86_capability)) &&
+	    !memcmp(&prev_info->x86_ext_capability, &curr_info.x86_ext_capability,
+		    sizeof(prev_info->x86_ext_capability)))
 		return;
 
 	pr_warn("x86/CPU: CPU features have changed after loading microcode, but might not take effect.\n");
--- a/arch/x86/kernel/cpu/mkcapflags.sh
+++ b/arch/x86/kernel/cpu/mkcapflags.sh
@@ -36,15 +36,10 @@ dump_array()
 		# Name is uppercase, VALUE is all lowercase
 		VALUE="$(echo "$VALUE" | tr A-Z a-z)"
 
-        if [ -n "$POSTFIX" ]; then
-            T=$(( $PFX_SZ + $(echo $POSTFIX | wc -c) + 2 ))
-	        TABS="$(printf '\t\t\t\t\t\t')"
-		    TABCOUNT=$(( ( 6*8 - ($T + 1) - $(echo "$NAME" | wc -c) ) / 8 ))
-		    printf "\t[%s - %s]%.*s = %s,\n" "$PFX$NAME" "$POSTFIX" "$TABCOUNT" "$TABS" "$VALUE"
-        else
-		    TABCOUNT=$(( ( 5*8 - ($PFX_SZ + 1) - $(echo "$NAME" | wc -c) ) / 8 ))
-            printf "\t[%s]%.*s = %s,\n" "$PFX$NAME" "$TABCOUNT" "$TABS" "$VALUE"
-        fi
+		T=$(( $PFX_SZ + $(echo $POSTFIX | wc -c) + 2 ))
+		TABS="$(printf '\t\t\t\t\t\t\t')"
+		TABCOUNT=$(( ( 7*8 - $T - $(echo "$NAME" | wc -c) ) / 8 ))
+		printf "\t[%s(%s)]%.*s = %s,\n" "$POSTFIX" "$PFX$NAME" "$TABCOUNT" "$TABS" "$VALUE"
 	done
 	echo "};"
 }
@@ -57,10 +52,10 @@ trap 'rm "$OUT"' EXIT
 	echo "#endif"
 	echo ""
 
-	dump_array "x86_cap_flags" "NCAPINTS*32" "X86_FEATURE_" "" $2
+	dump_array "x86_cap_flags" "(NCAPINTS+NEXTCAPINTS)*32" "X86_FEATURE_" "X86_FEATUREINDEX" $2
 	echo ""
 
-	dump_array "x86_bug_flags" "NBUGINTS*32" "X86_BUG_" "NCAPINTS*32" $2
+	dump_array "x86_bug_flags" "(NBUGINTS+NEXTBUGINTS)*32" "X86_BUG_" "X86_BUGINDEX" $2
 	echo ""
 
 	echo "#ifdef CONFIG_X86_VMX_FEATURE_NAMES"
--- a/arch/x86/kernel/cpu/proc.c
+++ b/arch/x86/kernel/cpu/proc.c
@@ -100,6 +100,12 @@ static int show_cpuinfo(struct seq_file
 	for (i = 0; i < 32*NCAPINTS; i++)
 		if (cpu_has(c, i) && x86_cap_flags[i] != NULL)
 			seq_printf(m, " %s", x86_cap_flags[i]);
+	for (i = 32*NCAPINTS; i < 32*(NCAPINTS+NEXTCAPINTS); i++) {
+		unsigned int cap_bit = 32*NBUGINTS + i;
+
+		if (cpu_has(c, cap_bit) && x86_cap_flags[i] != NULL)
+			seq_printf(m, " %s", x86_cap_flags[i]);
+	}
 
 #ifdef CONFIG_X86_VMX_FEATURE_NAMES
 	if (cpu_has(c, X86_FEATURE_VMX) && c->vmx_capability[0]) {
@@ -118,6 +124,12 @@ static int show_cpuinfo(struct seq_file
 
 		if (cpu_has_bug(c, bug_bit) && x86_bug_flags[i])
 			seq_printf(m, " %s", x86_bug_flags[i]);
+	}
+	for (i = 32*NBUGINTS; i < 32*(NBUGINTS+NEXTBUGINTS); i++) {
+		unsigned int bug_bit = 32*(NCAPINTS+NEXTCAPINTS) + i;
+
+		if (cpu_has_bug(c, bug_bit) && x86_bug_flags[i])
+			seq_printf(m, " %s", x86_bug_flags[i]);
 	}
 
 	seq_printf(m, "\nbogomips\t: %lu.%02lu\n",
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@ -882,7 +882,7 @@ static int emit_spectre_bhb_barrier(u8 *
 	u8 *prog = *pprog;
 	u8 *func;
 
-	if (cpu_feature_enabled(X86_FEATURE_CLEAR_BHB_LOOP)) {
+	if (boot_cpu_has(X86_FEATURE_CLEAR_BHB_LOOP)) {
 		/* The clearing sequence clobbers eax and ecx. */
 		EMIT1(0x50); /* push rax */
 		EMIT1(0x51); /* push rcx */
@@ -896,9 +896,9 @@ static int emit_spectre_bhb_barrier(u8 *
 		EMIT1(0x58); /* pop rax */
 	}
 	/* Insert IBHF instruction */
-	if ((cpu_feature_enabled(X86_FEATURE_CLEAR_BHB_LOOP) &&
+	if ((boot_cpu_has(X86_FEATURE_CLEAR_BHB_LOOP) &&
 	     cpu_feature_enabled(X86_FEATURE_HYPERVISOR)) ||
-	    cpu_feature_enabled(X86_FEATURE_CLEAR_BHB_HW)) {
+	    boot_cpu_has(X86_FEATURE_CLEAR_BHB_HW)) {
 		/*
 		 * Add an Indirect Branch History Fence (IBHF). IBHF acts as a
 		 * fence preventing branch history from before the fence from
