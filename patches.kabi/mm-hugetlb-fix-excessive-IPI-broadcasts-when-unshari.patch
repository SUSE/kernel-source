From befb1d287339d436cc3009557074aa363b3d2437 Mon Sep 17 00:00:00 2001
From: Oscar Salvador <osalvador@suse.de>
Date: Tue, 17 Feb 2026 11:23:23 +0100
Subject: [PATCH] kABI: Fixup for struct mmu_gather
Patch-mainline: Never, kABI workaround
References: Git-fixes

Mainline commit 8ce720d5bd91 ("mm/hugetlb: fix excessive IPI broadcasts when
unsharing PMD tables using mmu_gather") added two new members to struct mmu_gather.
Since these two new members are bit values, and the struct has a 21-bit hole before,
store them there.

```
struct mmu_gather {
	struct mm_struct *         mm;                   /*     0     8 */
	struct mmu_table_batch *   batch;                /*     8     8 */
	long unsigned int          start;                /*    16     8 */
	long unsigned int          end;                  /*    24     8 */
	unsigned int               fullmm:1;             /*    32: 0  4 */
	unsigned int               need_flush_all:1;     /*    32: 1  4 */
	unsigned int               freed_tables:1;       /*    32: 2  4 */
	unsigned int               delayed_rmap:1;       /*    32: 3  4 */
	unsigned int               cleared_ptes:1;       /*    32: 4  4 */
	unsigned int               cleared_pmds:1;       /*    32: 5  4 */
	unsigned int               cleared_puds:1;       /*    32: 6  4 */
	unsigned int               cleared_p4ds:1;       /*    32: 7  4 */
	unsigned int               vma_exec:1;           /*    32: 8  4 */
	unsigned int               vma_huge:1;           /*    32: 9  4 */
	unsigned int               vma_pfn:1;            /*    32:10  4 */

	/* XXX 21 bits hole, try to pack */

	unsigned int               batch_count;          /*    36     4 */
```

Signed-off-by: Oscar Salvador <osalvador@suse.de>
Reviewed-by: Jan Kara <jack@suse.cz>
---
 include/asm-generic/tlb.h |   66 ++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 66 insertions(+)

--- a/include/asm-generic/tlb.h
+++ b/include/asm-generic/tlb.h
@@ -345,6 +345,7 @@ struct mmu_gather {
 	unsigned int		vma_huge : 1;
 	unsigned int		vma_pfn  : 1;
 
+#ifndef __GENKSYMS__
 	/*
 	 * Did we unshare (unmap) any shared page tables? For now only
 	 * used for hugetlb PMD table sharing.
@@ -358,6 +359,66 @@ struct mmu_gather {
 	 * for hugetlb PMD table sharing.
 	 */
 	unsigned int		fully_unshared_tables : 1;
+#endif
+
+	unsigned int            batch_count;
+
+#ifndef CONFIG_MMU_GATHER_NO_GATHER
+	struct mmu_gather_batch *active;
+	struct mmu_gather_batch local;
+	struct page             *__pages[MMU_GATHER_BUNDLE];
+
+#ifdef CONFIG_MMU_GATHER_PAGE_SIZE
+	unsigned int page_size;
+#endif
+#endif
+};
+
+struct __orig_mmu_gather {
+	struct mm_struct        *mm;
+
+#ifdef CONFIG_MMU_GATHER_TABLE_FREE
+	struct mmu_table_batch  *batch;
+#endif
+
+	unsigned long           start;
+	unsigned long           end;
+	/*
+	 * we are in the middle of an operation to clear
+	 * a full mm and can make some optimizations
+	 */
+	unsigned int            fullmm : 1;
+
+	/*
+	 * we have performed an operation which
+	 * requires a complete flush of the tlb
+	 */
+	unsigned int            need_flush_all : 1;
+
+	/*
+	 * we have removed page directories
+	 */
+	unsigned int            freed_tables : 1;
+
+	/*
+	 * Do we have pending delayed rmap removals?
+	 */
+	unsigned int            delayed_rmap : 1;
+
+	/*
+	 * at which levels have we cleared entries?
+	 */
+	unsigned int            cleared_ptes : 1;
+	unsigned int            cleared_pmds : 1;
+	unsigned int            cleared_puds : 1;
+	unsigned int            cleared_p4ds : 1;
+
+	/*
+	 * tracks VM_EXEC | VM_HUGETLB in tlb_start_vma
+	 */
+	unsigned int            vma_exec : 1;
+	unsigned int            vma_huge : 1;
+	unsigned int            vma_pfn  : 1;
 
 	unsigned int		batch_count;
 
@@ -372,6 +433,11 @@ struct mmu_gather {
 #endif
 };
 
+suse_kabi_static_assert(offsetof(struct mmu_gather, batch_count) ==
+			offsetof(struct __orig_mmu_gather, batch_count));
+suse_kabi_static_assert(sizeof(struct mmu_gather) ==
+			sizeof(struct __orig_mmu_gather));
+
 void tlb_flush_mmu(struct mmu_gather *tlb);
 
 static inline void __tlb_adjust_range(struct mmu_gather *tlb,
