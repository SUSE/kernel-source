From: Joerg Roedel <jroedel@suse.de>
Date: Mon, 24 Jun 2024 13:39:15 +0200
Subject: kABI: Fix kABI after SNP KVM backports
Patch-mainline: Never, kABI fix
References: jsc#PED-5122

Signed-off-by: Joerg Roedel <jroedel@suse.de>
---
 arch/x86/include/asm/kvm_host.h |   13 +++++++------
 arch/x86/kvm/mmu/mmu.c          |    2 +-
 arch/x86/kvm/svm/svm.c          |    4 ++--
 arch/x86/kvm/x86.c              |   30 +++++++++++++++---------------
 include/linux/cc_platform.h     |    2 ++
 include/linux/kvm_host.h        |    5 +++++
 6 files changed, 32 insertions(+), 24 deletions(-)

--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -1288,14 +1288,12 @@ enum kvm_apicv_inhibit {
 };
 
 struct kvm_arch {
+	unsigned long vm_type;
 	unsigned long n_used_mmu_pages;
 	unsigned long n_requested_mmu_pages;
 	unsigned long n_max_mmu_pages;
 	unsigned int indirect_shadow_pages;
 	u8 mmu_valid_gen;
-	u8 vm_type;
-	bool has_private_mem;
-	bool has_protected_state;
 	struct hlist_head mmu_page_hash[KVM_NUM_MMU_PAGES];
 	struct list_head active_mmu_pages;
 	struct list_head zapped_obsolete_pages;
@@ -1787,9 +1785,7 @@ struct kvm_x86_ops {
 	void (*enable_smi_window)(struct kvm_vcpu *vcpu);
 #endif
 
-	int (*dev_get_attr)(u32 group, u64 attr, u64 *val);
 	int (*mem_enc_ioctl)(struct kvm *kvm, void __user *argp);
-	int (*vcpu_mem_enc_ioctl)(struct kvm_vcpu *vcpu, void __user *argp);
 	int (*mem_enc_register_region)(struct kvm *kvm, struct kvm_enc_region *argp);
 	int (*mem_enc_unregister_region)(struct kvm *kvm, struct kvm_enc_region *argp);
 	int (*vm_copy_enc_context_from)(struct kvm *kvm, unsigned int source_fd);
@@ -1817,6 +1814,10 @@ struct kvm_x86_ops {
 	gva_t (*get_untagged_addr)(struct kvm_vcpu *vcpu, gva_t gva, unsigned int flags);
 
 	void *(*alloc_apic_backing_page)(struct kvm_vcpu *vcpu);
+
+#ifndef __GENKSYMS__
+	int (*dev_get_attr)(u32 group, u64 attr, u64 *val);
+	int (*vcpu_mem_enc_ioctl)(struct kvm_vcpu *vcpu, void __user *argp);
 	int (*gmem_prepare)(struct kvm *kvm, kvm_pfn_t pfn, gfn_t gfn, int max_order);
 	void (*gmem_invalidate)(kvm_pfn_t start, kvm_pfn_t end);
 	int (*private_max_mapping_level)(struct kvm *kvm, kvm_pfn_t pfn, gfn_t gfn, bool is_private, u8 *max_level);
@@ -1858,6 +1859,7 @@
 				  u64 *error_code, u8 *max_level);
 	void (*post_memory_mapping)(struct kvm_vcpu *vcpu,
 				    struct kvm_memory_mapping *mapping);
+#endif
 };
 
 struct kvm_x86_nested_ops {
@@ -2170,12 +2171,12 @@ void kvm_configure_mmu(bool enable_tdp,
 
 
 #ifdef CONFIG_KVM_PRIVATE_MEM
-#define kvm_arch_has_private_mem(kvm) ((kvm)->arch.has_private_mem)
+#define kvm_arch_has_private_mem(kvm) ((kvm)->has_private_mem)
 #else
 #define kvm_arch_has_private_mem(kvm) false
 #endif
 
-#define kvm_arch_has_readonly_mem(kvm) (!(kvm)->arch.has_protected_state)
+#define kvm_arch_has_readonly_mem(kvm) (!(kvm)->has_protected_state)
 
 static inline u16 kvm_read_ldt(void)
 {
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@ -3375,7 +3375,7 @@ static bool page_fault_can_be_fast(struc
 	 * on RET_PF_SPURIOUS until the update completes, or an actual spurious
 	 * case might go down the slow path. Either case will resolve itself.
 	 */
-	if (kvm->arch.has_private_mem &&
+	if (kvm->has_private_mem &&
 	    fault->is_private != kvm_mem_is_private(kvm, fault->gfn))
 		return false;
 
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -4939,11 +4939,11 @@ static int svm_vm_init(struct kvm *kvm)
 
 	if (type != KVM_X86_DEFAULT_VM &&
 	    type != KVM_X86_SW_PROTECTED_VM) {
-		kvm->arch.has_protected_state =
+		kvm->has_protected_state =
 			(type == KVM_X86_SEV_ES_VM || type == KVM_X86_SNP_VM);
 		to_kvm_sev_info(kvm)->need_init = true;
 
-		kvm->arch.has_private_mem = (type == KVM_X86_SNP_VM);
+		kvm->has_private_mem = (type == KVM_X86_SNP_VM);
 	}
 
 	if (!pause_filter_count || !pause_filter_thresh)
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -5559,7 +5559,7 @@ static int kvm_vcpu_ioctl_x86_get_debugr
 	unsigned long val;
 	unsigned int i;
 
-	if (vcpu->kvm->arch.has_protected_state &&
+	if (vcpu->kvm->has_protected_state &&
 	    vcpu->arch.guest_state_protected)
 		return -EINVAL;
 
@@ -5580,7 +5580,7 @@ static int kvm_vcpu_ioctl_x86_set_debugr
 {
 	unsigned int i;
 
-	if (vcpu->kvm->arch.has_protected_state &&
+	if (vcpu->kvm->has_protected_state &&
 	    vcpu->arch.guest_state_protected)
 		return -EINVAL;
 
@@ -5623,7 +5623,7 @@ static int kvm_vcpu_ioctl_x86_get_xsave2
 			     XFEATURE_MASK_FPSSE;
 
 	if (fpstate_is_confidential(&vcpu->arch.guest_fpu))
-		return vcpu->kvm->arch.has_protected_state ? -EINVAL : 0;
+		return vcpu->kvm->has_protected_state ? -EINVAL : 0;
 
 	fpu_copy_guest_fpstate_to_uabi(&vcpu->arch.guest_fpu, state, size,
 				       supported_xcr0, vcpu->arch.pkru);
@@ -5641,7 +5641,7 @@ static int kvm_vcpu_ioctl_x86_set_xsave(
 					struct kvm_xsave *guest_xsave)
 {
 	if (fpstate_is_confidential(&vcpu->arch.guest_fpu))
-		return vcpu->kvm->arch.has_protected_state ? -EINVAL : 0;
+		return vcpu->kvm->has_protected_state ? -EINVAL : 0;
 
 	return fpu_copy_uabi_to_guest_fpstate(&vcpu->arch.guest_fpu,
 					      guest_xsave->region,
@@ -5652,7 +5652,7 @@ static int kvm_vcpu_ioctl_x86_set_xsave(
 static int kvm_vcpu_ioctl_x86_get_xcrs(struct kvm_vcpu *vcpu,
 				       struct kvm_xcrs *guest_xcrs)
 {
-	if (vcpu->kvm->arch.has_protected_state &&
+	if (vcpu->kvm->has_protected_state &&
 	    vcpu->arch.guest_state_protected)
 		return -EINVAL;
 
@@ -5673,7 +5673,7 @@ static int kvm_vcpu_ioctl_x86_set_xcrs(s
 {
 	int i, r = 0;
 
-	if (vcpu->kvm->arch.has_protected_state &&
+	if (vcpu->kvm->has_protected_state &&
 	    vcpu->arch.guest_state_protected)
 		return -EINVAL;
 
@@ -6289,7 +6289,7 @@ long kvm_arch_vcpu_ioctl(struct file *fi
 #endif
 	case KVM_GET_SREGS2: {
 		r = -EINVAL;
-		if (vcpu->kvm->arch.has_protected_state &&
+		if (vcpu->kvm->has_protected_state &&
 		    vcpu->arch.guest_state_protected)
 			goto out;
 
@@ -6306,7 +6306,7 @@ long kvm_arch_vcpu_ioctl(struct file *fi
 	}
 	case KVM_SET_SREGS2: {
 		r = -EINVAL;
-		if (vcpu->kvm->arch.has_protected_state &&
+		if (vcpu->kvm->has_protected_state &&
 		    vcpu->arch.guest_state_protected)
 			goto out;
 
@@ -11556,7 +11556,7 @@ static void __get_regs(struct kvm_vcpu *
 
 int kvm_arch_vcpu_ioctl_get_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)
 {
-	if (vcpu->kvm->arch.has_protected_state &&
+	if (vcpu->kvm->has_protected_state &&
 	    vcpu->arch.guest_state_protected)
 		return -EINVAL;
 
@@ -11601,7 +11601,7 @@ static void __set_regs(struct kvm_vcpu *
 
 int kvm_arch_vcpu_ioctl_set_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)
 {
-	if (vcpu->kvm->arch.has_protected_state &&
+	if (vcpu->kvm->has_protected_state &&
 	    vcpu->arch.guest_state_protected)
 		return -EINVAL;
 
@@ -11677,7 +11677,7 @@ static void __get_sregs2(struct kvm_vcpu
 int kvm_arch_vcpu_ioctl_get_sregs(struct kvm_vcpu *vcpu,
 				  struct kvm_sregs *sregs)
 {
-	if (vcpu->kvm->arch.has_protected_state &&
+	if (vcpu->kvm->has_protected_state &&
 	    vcpu->arch.guest_state_protected)
 		return -EINVAL;
 
@@ -11948,7 +11948,7 @@ int kvm_arch_vcpu_ioctl_set_sregs(struct
 {
 	int ret;
 
-	if (vcpu->kvm->arch.has_protected_state &&
+	if (vcpu->kvm->has_protected_state &&
 	    vcpu->arch.guest_state_protected)
 		return -EINVAL;
 
@@ -12069,7 +12069,7 @@ int kvm_arch_vcpu_ioctl_get_fpu(struct k
 	struct fxregs_state *fxsave;
 
 	if (fpstate_is_confidential(&vcpu->arch.guest_fpu))
-		return vcpu->kvm->arch.has_protected_state ? -EINVAL : 0;
+		return vcpu->kvm->has_protected_state ? -EINVAL : 0;
 
 	vcpu_load(vcpu);
 
@@ -12092,7 +12092,7 @@ int kvm_arch_vcpu_ioctl_set_fpu(struct k
 	struct fxregs_state *fxsave;
 
 	if (fpstate_is_confidential(&vcpu->arch.guest_fpu))
-		return vcpu->kvm->arch.has_protected_state ? -EINVAL : 0;
+		return vcpu->kvm->has_protected_state ? -EINVAL : 0;
 
 	vcpu_load(vcpu);
 
@@ -12641,7 +12641,7 @@ int kvm_arch_init_vm(struct kvm *kvm, un
 		return -EINVAL;
 
 	kvm->arch.vm_type = type;
-	kvm->arch.has_private_mem =
+	kvm->has_private_mem =
 		(type == KVM_X86_SW_PROTECTED_VM);
 
 	ret = kvm_page_track_init(kvm);
--- a/include/linux/cc_platform.h
+++ b/include/linux/cc_platform.h
@@ -91,6 +91,7 @@ enum cc_attr {
 	 */
 	CC_ATTR_HOTPLUG_DISABLED,
 
+#ifndef __GENKSYMS__
 	/**
 	 * @CC_ATTR_HOST_SEV_SNP: AMD SNP enabled on the host.
 	 *
@@ -98,6 +99,7 @@ enum cc_attr {
 	 * enabled to run SEV-SNP guests.
 	 */
 	CC_ATTR_HOST_SEV_SNP,
+#endif
 };
 
 #ifdef CONFIG_ARCH_HAS_CC_PLATFORM
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -849,6 +849,11 @@ struct kvm {
 	struct xarray mem_attr_array;
 #endif
 	char stats_id[KVM_STATS_NAME_SIZE];
+
+#ifndef __GENKSYMS__
+	bool has_private_mem;
+	bool has_protected_state;
+#endif
 };
 
 #define kvm_err(fmt, ...) \
